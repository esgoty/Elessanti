{"cells":[{"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Word2vect\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import sys\n","import numpy as np\n","import pandas as pd\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'el', 'es', 'muchas', 'gracias', 'martes', 'de', 'dia', 'hoy', 'que'}\n","\n","[list(['que', 'dia', 'es', 'hoy'])\n"," list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'])\n"," list(['martes', 'muchas', 'gracias'])]\n"]}],"source":["def listyfy( corpus ): \n","    return np.char.split(corpus)\n","\n","def dictionarify(corpus): \n","    dictionary = set()\n","\n","    for document in corpus:\n","        dictionary.update(document)\n","    return dictionary\n","\n","\n","listed_corpus = listyfy( corpus )\n","dict_corpus = dictionarify(listed_corpus)\n","\n","\n","\n","print(dict_corpus)\n","print(\"\")\n","print(listed_corpus)\n"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["['martes', 'muchas', 'gracias']\n","\n","{'el', 'es', 'muchas', 'gracias', 'martes', 'de', 'dia', 'hoy', 'que'}\n","\n","[[0. 1. 0. 0. 0. 0. 1. 1. 1.]\n"," [1. 1. 0. 0. 1. 1. 1. 1. 0.]\n"," [0. 0. 1. 1. 1. 0. 0. 0. 0.]]\n"]}],"source":["def onehotify (listed_corpus=listed_corpus , dict_corpus=dict_corpus):\n","    output = np.zeros((corpus.shape[0],len(dict_corpus)))\n","\n","    for j, document in enumerate(listed_corpus):\n","        for i, term in enumerate(dict_corpus) :        \n","            if (document.count(term)>0) : output[j,i]= 1\n","            else : output[j,i]= 0\n","    \n","    return output\n","\n","#ejemplo\n","\n","onehot_corpus = onehotify(listed_corpus,dict_corpus)\n","\n","print(listed_corpus[2])\n","print(\"\")\n","print(dict_corpus)\n","print(\"\")\n","print(onehot_corpus)"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["['martes', 'muchas', 'gracias']\n","\n","{'el', 'es', 'muchas', 'gracias', 'martes', 'de', 'dia', 'hoy', 'que'}\n","\n","[[0. 1. 0. 0. 0. 0. 1. 1. 1.]\n"," [1. 1. 0. 0. 2. 1. 1. 1. 0.]\n"," [0. 0. 1. 1. 1. 0. 0. 0. 0.]]\n"]}],"source":["def frecuencify (listed_corpus=listed_corpus , dict_corpus=dict_corpus):\n","    output = np.zeros((corpus.shape[0],len(dict_corpus)))\n","\n","    for i, term in enumerate(dict_corpus) :\n","        for j, document in enumerate(listed_corpus):\n","\n","            output[j,i]= document.count(term)\n","    \n","    return output\n","\n","#ejemplo            \n","print(listyfy(corpus)[2])\n","print(\"\")\n","print(dictionarify(listyfy(corpus)))\n","print(\"\")\n","print(frecuencify( listyfy(corpus) , dictionarify(listyfy(corpus))))"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["[list(['que', 'dia', 'es', 'hoy'])\n"," list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'])\n"," list(['martes', 'muchas', 'gracias'])]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>el</th>\n","      <th>es</th>\n","      <th>muchas</th>\n","      <th>gracias</th>\n","      <th>martes</th>\n","      <th>de</th>\n","      <th>dia</th>\n","      <th>hoy</th>\n","      <th>que</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>0.405465</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.405465</td>\n","      <td>0.405465</td>\n","      <td>1.098612</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.098612</td>\n","      <td>0.405465</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.810930</td>\n","      <td>1.098612</td>\n","      <td>0.405465</td>\n","      <td>0.405465</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.098612</td>\n","      <td>1.098612</td>\n","      <td>0.405465</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         el        es    muchas   gracias    martes        de       dia  \\\n","0  0.000000  0.405465  0.000000  0.000000  0.000000  0.000000  0.405465   \n","1  1.098612  0.405465  0.000000  0.000000  0.810930  1.098612  0.405465   \n","2  0.000000  0.000000  1.098612  1.098612  0.405465  0.000000  0.000000   \n","\n","        hoy       que  \n","0  0.405465  1.098612  \n","1  0.405465  0.000000  \n","2  0.000000  0.000000  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["\n","\n","def find_idf( listed_corpus , dict_corpus ):\n","    idf_vector = np.zeros([len(dict_corpus),])\n","\n","    one_hot_temp = onehotify(listed_corpus,dict_corpus)\n","    vsum_one_hot_temp = np.sum(one_hot_temp,axis=0)\n","    \n","    for idx in range(len(idf_vector)):\n","        idf_vector[idx] = np.log( listed_corpus.shape[0] / vsum_one_hot_temp[idx])\n","\n","    return idf_vector\n","\n","    \n","\n","def get_TFIDF( listed_corpus , dict_corpus ):\n","    idf = find_idf(listed_corpus=listed_corpus , dict_corpus=dict_corpus)\n","    tf = frecuencify(listed_corpus=listed_corpus , dict_corpus=dict_corpus)\n","\n","    TFIDF = tf * idf.T\n","    return TFIDF\n","\n","\n","print(listed_corpus)\n","df = pd.DataFrame(get_TFIDF( listed_corpus , dict_corpus ), columns = list(dict_corpus))\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["(3,)\n"]}],"source":["#Como la evaluacion del coseno necesita numeros y no texto, voy a usar alguna de las representaciones de word2 vec realizadas\n","# de manera random, voy a usar la tf-idf, porque escuche que se ha usado mucho. \n","\n","def how_similar(corpus , corpus_doc_idx):\n","    similarty_indexes = np.zeros([corpus.shape[0],])\n","\n","    print(similarty_indexes.shape)\n","\n","    listed_corpus = listyfy( corpus )\n","    dict_corpus = dictionarify(listed_corpus)\n","    \n","    TDFIDF_word2vec = get_TFIDF( listed_corpus , dict_corpus )\n","\n","    for idx in range(len(TDFIDF_word2vec)):\n","        similarty_indexes[idx] = cosine_similarity(TDFIDF_word2vec[corpus_doc_idx,:],TDFIDF_word2vec[idx,:] ) \n","\n","    return TDFIDF_word2vec\n","\n","\n","a = how_similar(corpus=corpus, corpus_doc_idx=0)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.8.13 ('NLP')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"db02c8c4514aa220eff79aceef1a08987b492a1ceac9f4c924fdffa694c5d5c2"}}},"nbformat":4,"nbformat_minor":0}
