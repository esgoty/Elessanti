{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "## LSTM Bot QA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "### Datos\n",
        "El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n",
        "[LINK](http://convai.io/data/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bDFC0I3j9oFD"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM, SimpleRNN\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RHNkUaPp6aYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bcf1009-e02a-44f4-fba6-4a0a7732933d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download\n",
            "To: /content/data_volunteers.json\n",
            "100%|██████████| 2.58M/2.58M [00:00<00:00, 206MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import gdown\n",
        "if os.access('data_volunteers.json', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n",
        "    output = 'data_volunteers.json'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WZy1-wgG-Rp7"
      },
      "outputs": [],
      "source": [
        "# dataset_file\n",
        "text_file = \"data_volunteers.json\"\n",
        "with open(text_file) as f:\n",
        "    data = json.load(f) # la variable data será un diccionario\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ue5qd54S-eew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd63dcbf-7cf8-4a43-9123-e111595387bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Observar los campos disponibles en cada linea del dataset\n",
        "data[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jHBRAXPl-3dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73866922-c14f-43b7-827e-b9db56ede1df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows utilizadas: 6033\n"
          ]
        }
      ],
      "source": [
        "chat_in = []\n",
        "chat_out = []\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "max_len = 30\n",
        "\n",
        "def clean_text(txt):\n",
        "    txt = txt.lower()    \n",
        "    txt.replace(\"\\'d\", \" had\")\n",
        "    txt.replace(\"\\'s\", \" is\")\n",
        "    txt.replace(\"\\'m\", \" am\")\n",
        "    txt.replace(\"don't\", \"do not\")\n",
        "    txt = re.sub(r'\\W+', ' ', txt)\n",
        "    \n",
        "    return txt\n",
        "\n",
        "for line in data:\n",
        "    for i in range(len(line['dialog'])-1):\n",
        "        # vamos separando el texto en \"preguntas\" (chat_in)\n",
        "        # y \"respuestas\" (chat_out)\n",
        "        chat_in = clean_text(line['dialog'][i]['text'])\n",
        "        chat_out = clean_text(line['dialog'][i+1]['text'])\n",
        "\n",
        "        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
        "            continue\n",
        "\n",
        "        input_sentence, output = chat_in, chat_out\n",
        "        \n",
        "        # output sentence (decoder_output) tiene <eos>\n",
        "        output_sentence = output + ' <eos>'\n",
        "        # output sentence input (decoder_input) tiene <sos>\n",
        "        output_sentence_input = '<sos> ' + output\n",
        "\n",
        "        input_sentences.append(input_sentence)\n",
        "        output_sentences.append(output_sentence)\n",
        "        output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "07L1qj8pC_l6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b526f0-094f-49a9-e9b4-d8feadff0fc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "input_sentences[1], output_sentences[1], output_sentences_inputs[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "#2 - Preprocesamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el tamaño máximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 1800"
      ],
      "metadata": {
        "id": "lkUl1LyeH-tm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizador de preguntas \n",
        "(word2idx_inputs, max_input_len)"
      ],
      "metadata": {
        "id": "Ajlg5fWC4ggr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario de preguntas:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq) + 1 #para extra paddinggggg\n",
        "print(\"Sentencia de entrada más larga: de pregunta\", max_input_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhRuZsBd4dGy",
        "outputId": "4bba910e-b8f0-46f4-a115-bd42256ad79a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario de preguntas: 1799\n",
            "Sentencia de entrada más larga: de pregunta 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Tokenizador de respuestas  \n",
        "(word2idx_outputs, max_out_len, num_words_output)\n"
      ],
      "metadata": {
        "id": "PZt7uu-X4lXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
        "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario de respuestas:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) \n",
        "# Se suma 1 para incluir el token de palabra desconocida\n",
        "\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Sentencia de salida más larga de respuestas:\", max_out_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sirxY8Ji4jdu",
        "outputId": "fb0d0df7-91d2-41be-ac4d-a7a4b25a6a44"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario de respuestas: 1806\n",
            "Sentencia de salida más larga de respuestas: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definicion de encoders y decoders \n",
        "(encoder_input_sequences, decoder_output_sequences, decoder_targets)"
      ],
      "metadata": {
        "id": "LkeWrfPZ4teq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"filas del dataset:\", len(input_integer_seq))\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"shape input encoder:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"shape input decoder:\", decoder_input_sequences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0Fk1BYK4xDm",
        "outputId": "710f27f9-0ee3-4efb-b798-985aaf291ad7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filas del dataset: 6033\n",
            "shape input encoder: (6033, 10)\n",
            "shape input decoder: (6033, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
        "print( \"Decoder Shape\", decoder_targets.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfTiWMvW4yk4",
        "outputId": "9bf97c00-0728-4de7-8b04-95f8d85fe50d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder Shape (6033, 10, 1800)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "# 3- Preparacion de embedings FastText"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "if os.access('fasttext.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1KU5qmAYh3LATMvVgocFDfW-PK3prm1WU&export=download'\n",
        "    output = 'fasttext.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings fasttext.pkl ya están descargados\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UbCj45e1mtI",
        "outputId": "7c34fd5d-3995-4725-b21d-f8b3e39a9f2b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KU5qmAYh3LATMvVgocFDfW-PK3prm1WU&export=download\n",
            "To: /content/fasttext.pkl\n",
            "100%|██████████| 2.88G/2.88G [00:19<00:00, 144MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ],
      "metadata": {
        "id": "SEODAtfp3aoG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fasttext = FasttextEmbeddings()"
      ],
      "metadata": {
        "id": "Opj23gVy3c1_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la matriz de embeddings\n",
        "\n",
        "print('preparing embedding matrix...')\n",
        "embed_dim = 300 # fasttext\n",
        "words_not_found = []\n",
        "\n",
        "# word_index provieen del tokenizer\n",
        "\n",
        "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = model_fasttext.get_words_embeddings(word)[0]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        words_not_found.append(word)\n",
        "        print(word)\n",
        "\n",
        "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "metadata": {
        "id": "fsyRJZN63fkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb6b25c-3417-48e0-dd6b-ff51f7289389"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preparing embedding matrix...\n",
            "number of null word embeddings: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo\n",
        "Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_input_len)"
      ],
      "metadata": {
        "id": "a9SWxnHv1n21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f627823b-646e-4e99-a343-c3e0ec5c4f2b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "\n",
        "n_units = 128\n",
        "\n",
        "# define training encoder\n",
        "encoder_inputs = Input(shape=(max_input_len))\n",
        "\n",
        "#encoder_embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n",
        "\n",
        "encoder_embedding_layer = Embedding(\n",
        "          input_dim=nb_words,  # definido en el Tokenizador\n",
        "          output_dim=embed_dim,  # dimensión de los embeddings utilizados\n",
        "          input_length=max_input_len, # máxima sentencia de entrada\n",
        "          weights=[embedding_matrix],  # matrix de embeddings\n",
        "          trainable=False)      # marcar como layer no entrenable\n",
        "\n",
        "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
        "\n",
        "encoder = LSTM(n_units, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# define training decoder\n",
        "decoder_inputs = Input(shape=(max_out_len))\n",
        "decoder_embedding_layer = Embedding(input_dim=num_words_output, output_dim=n_units, input_length=max_out_len)\n",
        "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
        "\n",
        "# Dense\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "3Z_WyfuC33Cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5dd6233-a1f4-4b55-e046-8493cd1e761f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 10, 300)      539700      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 10, 128)      230400      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 128),        219648      ['embedding[0][0]']              \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 10, 128),    131584      ['embedding_1[0][0]',            \n",
            "                                 (None, 128),                     'lstm[0][1]',                   \n",
            "                                 (None, 128)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10, 1800)     232200      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,353,532\n",
            "Trainable params: 813,832\n",
            "Non-trainable params: 539,700\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo solo encoder\n",
        "\n",
        "# define inference encoder\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "BVWYt648366t"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo solo decoder\n",
        "\n",
        "# define inference decoder\n",
        "decoder_state_input_h = Input(shape=(n_units,))\n",
        "decoder_state_input_c = Input(shape=(n_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# En cada predicción habrá una sola palabra de entrada al decoder,\n",
        "# que es la realimentación de la palabra anterior\n",
        "# por lo que hay que modificar el input shape de la layer de Embedding\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "#plot_model(decoder_model, to_file='decoder_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "uLRndMOA39Zv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets,\n",
        "    epochs=200, \n",
        "    validation_split=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKBk__ld3-zA",
        "outputId": "4cd6912f-b17a-460b-ce75-cd9c98dc4c02"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "132/132 [==============================] - 13s 18ms/step - loss: 3.2373 - accuracy: 0.4906 - val_loss: 2.3410 - val_accuracy: 0.5802\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 2.1764 - accuracy: 0.6120 - val_loss: 2.1161 - val_accuracy: 0.6458\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.9352 - accuracy: 0.6580 - val_loss: 1.9263 - val_accuracy: 0.6871\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.7356 - accuracy: 0.6978 - val_loss: 1.8130 - val_accuracy: 0.7082\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.6121 - accuracy: 0.7140 - val_loss: 1.7467 - val_accuracy: 0.7149\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.5270 - accuracy: 0.7217 - val_loss: 1.7099 - val_accuracy: 0.7175\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.4617 - accuracy: 0.7277 - val_loss: 1.6718 - val_accuracy: 0.7254\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.4076 - accuracy: 0.7360 - val_loss: 1.6504 - val_accuracy: 0.7270\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 1.3634 - accuracy: 0.7388 - val_loss: 1.6353 - val_accuracy: 0.7291\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.3267 - accuracy: 0.7417 - val_loss: 1.6214 - val_accuracy: 0.7309\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 1.2929 - accuracy: 0.7445 - val_loss: 1.6132 - val_accuracy: 0.7313\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 1.2633 - accuracy: 0.7472 - val_loss: 1.6039 - val_accuracy: 0.7336\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.2355 - accuracy: 0.7522 - val_loss: 1.6025 - val_accuracy: 0.7353\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 1.2118 - accuracy: 0.7544 - val_loss: 1.5930 - val_accuracy: 0.7397\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 1.1884 - accuracy: 0.7582 - val_loss: 1.5917 - val_accuracy: 0.7400\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 1.1671 - accuracy: 0.7616 - val_loss: 1.5900 - val_accuracy: 0.7391\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.1472 - accuracy: 0.7628 - val_loss: 1.5949 - val_accuracy: 0.7413\n",
            "Epoch 18/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.1277 - accuracy: 0.7643 - val_loss: 1.5869 - val_accuracy: 0.7431\n",
            "Epoch 19/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.1095 - accuracy: 0.7667 - val_loss: 1.5897 - val_accuracy: 0.7429\n",
            "Epoch 20/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.0925 - accuracy: 0.7684 - val_loss: 1.5961 - val_accuracy: 0.7436\n",
            "Epoch 21/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 1.0764 - accuracy: 0.7697 - val_loss: 1.5953 - val_accuracy: 0.7439\n",
            "Epoch 22/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 1.0606 - accuracy: 0.7719 - val_loss: 1.5966 - val_accuracy: 0.7447\n",
            "Epoch 23/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 1.0449 - accuracy: 0.7739 - val_loss: 1.5978 - val_accuracy: 0.7445\n",
            "Epoch 24/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 1.0308 - accuracy: 0.7754 - val_loss: 1.6061 - val_accuracy: 0.7434\n",
            "Epoch 25/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 1.0165 - accuracy: 0.7770 - val_loss: 1.6063 - val_accuracy: 0.7470\n",
            "Epoch 26/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 1.0027 - accuracy: 0.7796 - val_loss: 1.6095 - val_accuracy: 0.7459\n",
            "Epoch 27/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.9890 - accuracy: 0.7803 - val_loss: 1.6142 - val_accuracy: 0.7464\n",
            "Epoch 28/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.9763 - accuracy: 0.7829 - val_loss: 1.6210 - val_accuracy: 0.7461\n",
            "Epoch 29/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.9635 - accuracy: 0.7847 - val_loss: 1.6223 - val_accuracy: 0.7465\n",
            "Epoch 30/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.9506 - accuracy: 0.7865 - val_loss: 1.6273 - val_accuracy: 0.7496\n",
            "Epoch 31/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.9382 - accuracy: 0.7876 - val_loss: 1.6253 - val_accuracy: 0.7485\n",
            "Epoch 32/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.9265 - accuracy: 0.7900 - val_loss: 1.6292 - val_accuracy: 0.7482\n",
            "Epoch 33/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.9157 - accuracy: 0.7924 - val_loss: 1.6345 - val_accuracy: 0.7489\n",
            "Epoch 34/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.9039 - accuracy: 0.7944 - val_loss: 1.6423 - val_accuracy: 0.7497\n",
            "Epoch 35/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.8929 - accuracy: 0.7962 - val_loss: 1.6466 - val_accuracy: 0.7480\n",
            "Epoch 36/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.8825 - accuracy: 0.7976 - val_loss: 1.6473 - val_accuracy: 0.7485\n",
            "Epoch 37/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.8725 - accuracy: 0.7994 - val_loss: 1.6557 - val_accuracy: 0.7483\n",
            "Epoch 38/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.8621 - accuracy: 0.8006 - val_loss: 1.6598 - val_accuracy: 0.7481\n",
            "Epoch 39/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.8523 - accuracy: 0.8035 - val_loss: 1.6608 - val_accuracy: 0.7502\n",
            "Epoch 40/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.8431 - accuracy: 0.8038 - val_loss: 1.6676 - val_accuracy: 0.7499\n",
            "Epoch 41/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.8340 - accuracy: 0.8064 - val_loss: 1.6737 - val_accuracy: 0.7482\n",
            "Epoch 42/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.8250 - accuracy: 0.8076 - val_loss: 1.6770 - val_accuracy: 0.7498\n",
            "Epoch 43/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.8157 - accuracy: 0.8089 - val_loss: 1.6838 - val_accuracy: 0.7498\n",
            "Epoch 44/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.8078 - accuracy: 0.8108 - val_loss: 1.6890 - val_accuracy: 0.7498\n",
            "Epoch 45/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.7998 - accuracy: 0.8116 - val_loss: 1.6933 - val_accuracy: 0.7502\n",
            "Epoch 46/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.7916 - accuracy: 0.8123 - val_loss: 1.7005 - val_accuracy: 0.7493\n",
            "Epoch 47/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.7832 - accuracy: 0.8135 - val_loss: 1.7095 - val_accuracy: 0.7492\n",
            "Epoch 48/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.7757 - accuracy: 0.8142 - val_loss: 1.7096 - val_accuracy: 0.7491\n",
            "Epoch 49/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.7684 - accuracy: 0.8161 - val_loss: 1.7164 - val_accuracy: 0.7483\n",
            "Epoch 50/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.7613 - accuracy: 0.8179 - val_loss: 1.7251 - val_accuracy: 0.7486\n",
            "Epoch 51/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.7546 - accuracy: 0.8186 - val_loss: 1.7323 - val_accuracy: 0.7492\n",
            "Epoch 52/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.7476 - accuracy: 0.8199 - val_loss: 1.7355 - val_accuracy: 0.7486\n",
            "Epoch 53/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.7408 - accuracy: 0.8203 - val_loss: 1.7439 - val_accuracy: 0.7492\n",
            "Epoch 54/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.7339 - accuracy: 0.8209 - val_loss: 1.7495 - val_accuracy: 0.7503\n",
            "Epoch 55/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.7278 - accuracy: 0.8220 - val_loss: 1.7585 - val_accuracy: 0.7497\n",
            "Epoch 56/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.7212 - accuracy: 0.8238 - val_loss: 1.7650 - val_accuracy: 0.7499\n",
            "Epoch 57/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.7149 - accuracy: 0.8247 - val_loss: 1.7690 - val_accuracy: 0.7497\n",
            "Epoch 58/200\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.7081 - accuracy: 0.8261 - val_loss: 1.7790 - val_accuracy: 0.7476\n",
            "Epoch 59/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.7014 - accuracy: 0.8271 - val_loss: 1.7842 - val_accuracy: 0.7501\n",
            "Epoch 60/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.6957 - accuracy: 0.8275 - val_loss: 1.7908 - val_accuracy: 0.7499\n",
            "Epoch 61/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.6890 - accuracy: 0.8284 - val_loss: 1.7965 - val_accuracy: 0.7472\n",
            "Epoch 62/200\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 0.6836 - accuracy: 0.8306 - val_loss: 1.8069 - val_accuracy: 0.7494\n",
            "Epoch 63/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.6776 - accuracy: 0.8308 - val_loss: 1.8141 - val_accuracy: 0.7491\n",
            "Epoch 64/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.6715 - accuracy: 0.8316 - val_loss: 1.8184 - val_accuracy: 0.7497\n",
            "Epoch 65/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.6660 - accuracy: 0.8325 - val_loss: 1.8236 - val_accuracy: 0.7488\n",
            "Epoch 66/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.6588 - accuracy: 0.8349 - val_loss: 1.8334 - val_accuracy: 0.7480\n",
            "Epoch 67/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.6535 - accuracy: 0.8353 - val_loss: 1.8422 - val_accuracy: 0.7483\n",
            "Epoch 68/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.6479 - accuracy: 0.8359 - val_loss: 1.8483 - val_accuracy: 0.7487\n",
            "Epoch 69/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.6425 - accuracy: 0.8369 - val_loss: 1.8580 - val_accuracy: 0.7485\n",
            "Epoch 70/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.6366 - accuracy: 0.8386 - val_loss: 1.8669 - val_accuracy: 0.7482\n",
            "Epoch 71/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.6312 - accuracy: 0.8389 - val_loss: 1.8706 - val_accuracy: 0.7485\n",
            "Epoch 72/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.6255 - accuracy: 0.8401 - val_loss: 1.8794 - val_accuracy: 0.7491\n",
            "Epoch 73/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.6202 - accuracy: 0.8419 - val_loss: 1.8891 - val_accuracy: 0.7488\n",
            "Epoch 74/200\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.6149 - accuracy: 0.8414 - val_loss: 1.8972 - val_accuracy: 0.7491\n",
            "Epoch 75/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.6092 - accuracy: 0.8437 - val_loss: 1.9015 - val_accuracy: 0.7483\n",
            "Epoch 76/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.6042 - accuracy: 0.8448 - val_loss: 1.9071 - val_accuracy: 0.7485\n",
            "Epoch 77/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5984 - accuracy: 0.8462 - val_loss: 1.9241 - val_accuracy: 0.7475\n",
            "Epoch 78/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5942 - accuracy: 0.8466 - val_loss: 1.9271 - val_accuracy: 0.7491\n",
            "Epoch 79/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5887 - accuracy: 0.8480 - val_loss: 1.9338 - val_accuracy: 0.7473\n",
            "Epoch 80/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5840 - accuracy: 0.8479 - val_loss: 1.9421 - val_accuracy: 0.7449\n",
            "Epoch 81/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5781 - accuracy: 0.8496 - val_loss: 1.9547 - val_accuracy: 0.7473\n",
            "Epoch 82/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5737 - accuracy: 0.8507 - val_loss: 1.9544 - val_accuracy: 0.7459\n",
            "Epoch 83/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.5687 - accuracy: 0.8516 - val_loss: 1.9622 - val_accuracy: 0.7448\n",
            "Epoch 84/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5635 - accuracy: 0.8531 - val_loss: 1.9745 - val_accuracy: 0.7480\n",
            "Epoch 85/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.5596 - accuracy: 0.8545 - val_loss: 1.9809 - val_accuracy: 0.7452\n",
            "Epoch 86/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.5541 - accuracy: 0.8544 - val_loss: 1.9958 - val_accuracy: 0.7455\n",
            "Epoch 87/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.5488 - accuracy: 0.8558 - val_loss: 1.9992 - val_accuracy: 0.7451\n",
            "Epoch 88/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5442 - accuracy: 0.8569 - val_loss: 2.0079 - val_accuracy: 0.7451\n",
            "Epoch 89/200\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 0.5403 - accuracy: 0.8582 - val_loss: 2.0168 - val_accuracy: 0.7452\n",
            "Epoch 90/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5352 - accuracy: 0.8595 - val_loss: 2.0247 - val_accuracy: 0.7455\n",
            "Epoch 91/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.5311 - accuracy: 0.8606 - val_loss: 2.0280 - val_accuracy: 0.7421\n",
            "Epoch 92/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.5259 - accuracy: 0.8618 - val_loss: 2.0387 - val_accuracy: 0.7455\n",
            "Epoch 93/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.5214 - accuracy: 0.8625 - val_loss: 2.0509 - val_accuracy: 0.7434\n",
            "Epoch 94/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.5173 - accuracy: 0.8630 - val_loss: 2.0564 - val_accuracy: 0.7430\n",
            "Epoch 95/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5132 - accuracy: 0.8641 - val_loss: 2.0654 - val_accuracy: 0.7453\n",
            "Epoch 96/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5087 - accuracy: 0.8648 - val_loss: 2.0733 - val_accuracy: 0.7421\n",
            "Epoch 97/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.5035 - accuracy: 0.8671 - val_loss: 2.0817 - val_accuracy: 0.7422\n",
            "Epoch 98/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.4996 - accuracy: 0.8676 - val_loss: 2.0882 - val_accuracy: 0.7441\n",
            "Epoch 99/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.4945 - accuracy: 0.8694 - val_loss: 2.0995 - val_accuracy: 0.7427\n",
            "Epoch 100/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.4911 - accuracy: 0.8696 - val_loss: 2.1081 - val_accuracy: 0.7435\n",
            "Epoch 101/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.4859 - accuracy: 0.8711 - val_loss: 2.1110 - val_accuracy: 0.7424\n",
            "Epoch 102/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.4828 - accuracy: 0.8710 - val_loss: 2.1262 - val_accuracy: 0.7432\n",
            "Epoch 103/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.4783 - accuracy: 0.8727 - val_loss: 2.1303 - val_accuracy: 0.7406\n",
            "Epoch 104/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.4739 - accuracy: 0.8730 - val_loss: 2.1338 - val_accuracy: 0.7416\n",
            "Epoch 105/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.4704 - accuracy: 0.8735 - val_loss: 2.1441 - val_accuracy: 0.7418\n",
            "Epoch 106/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4660 - accuracy: 0.8759 - val_loss: 2.1546 - val_accuracy: 0.7411\n",
            "Epoch 107/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4613 - accuracy: 0.8765 - val_loss: 2.1630 - val_accuracy: 0.7413\n",
            "Epoch 108/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4582 - accuracy: 0.8781 - val_loss: 2.1703 - val_accuracy: 0.7399\n",
            "Epoch 109/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4534 - accuracy: 0.8779 - val_loss: 2.1803 - val_accuracy: 0.7387\n",
            "Epoch 110/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4502 - accuracy: 0.8798 - val_loss: 2.1855 - val_accuracy: 0.7391\n",
            "Epoch 111/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4463 - accuracy: 0.8803 - val_loss: 2.1892 - val_accuracy: 0.7384\n",
            "Epoch 112/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4417 - accuracy: 0.8811 - val_loss: 2.1996 - val_accuracy: 0.7396\n",
            "Epoch 113/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4376 - accuracy: 0.8822 - val_loss: 2.2092 - val_accuracy: 0.7392\n",
            "Epoch 114/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4348 - accuracy: 0.8835 - val_loss: 2.2167 - val_accuracy: 0.7388\n",
            "Epoch 115/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4308 - accuracy: 0.8845 - val_loss: 2.2289 - val_accuracy: 0.7395\n",
            "Epoch 116/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4275 - accuracy: 0.8855 - val_loss: 2.2250 - val_accuracy: 0.7386\n",
            "Epoch 117/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4237 - accuracy: 0.8853 - val_loss: 2.2425 - val_accuracy: 0.7390\n",
            "Epoch 118/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4201 - accuracy: 0.8879 - val_loss: 2.2486 - val_accuracy: 0.7397\n",
            "Epoch 119/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4167 - accuracy: 0.8869 - val_loss: 2.2592 - val_accuracy: 0.7391\n",
            "Epoch 120/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4126 - accuracy: 0.8895 - val_loss: 2.2628 - val_accuracy: 0.7383\n",
            "Epoch 121/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4096 - accuracy: 0.8895 - val_loss: 2.2704 - val_accuracy: 0.7393\n",
            "Epoch 122/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4056 - accuracy: 0.8912 - val_loss: 2.2763 - val_accuracy: 0.7377\n",
            "Epoch 123/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4027 - accuracy: 0.8919 - val_loss: 2.2859 - val_accuracy: 0.7385\n",
            "Epoch 124/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3988 - accuracy: 0.8931 - val_loss: 2.2950 - val_accuracy: 0.7364\n",
            "Epoch 125/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3953 - accuracy: 0.8940 - val_loss: 2.2990 - val_accuracy: 0.7388\n",
            "Epoch 126/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3929 - accuracy: 0.8943 - val_loss: 2.3052 - val_accuracy: 0.7377\n",
            "Epoch 127/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3891 - accuracy: 0.8955 - val_loss: 2.3153 - val_accuracy: 0.7381\n",
            "Epoch 128/200\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3861 - accuracy: 0.8954 - val_loss: 2.3275 - val_accuracy: 0.7385\n",
            "Epoch 129/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3826 - accuracy: 0.8978 - val_loss: 2.3300 - val_accuracy: 0.7369\n",
            "Epoch 130/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3793 - accuracy: 0.8987 - val_loss: 2.3394 - val_accuracy: 0.7362\n",
            "Epoch 131/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3768 - accuracy: 0.8986 - val_loss: 2.3466 - val_accuracy: 0.7377\n",
            "Epoch 132/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3727 - accuracy: 0.8997 - val_loss: 2.3511 - val_accuracy: 0.7361\n",
            "Epoch 133/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3703 - accuracy: 0.9004 - val_loss: 2.3558 - val_accuracy: 0.7366\n",
            "Epoch 134/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3667 - accuracy: 0.9016 - val_loss: 2.3682 - val_accuracy: 0.7359\n",
            "Epoch 135/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3642 - accuracy: 0.9021 - val_loss: 2.3749 - val_accuracy: 0.7361\n",
            "Epoch 136/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3618 - accuracy: 0.9022 - val_loss: 2.3847 - val_accuracy: 0.7365\n",
            "Epoch 137/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3584 - accuracy: 0.9028 - val_loss: 2.3912 - val_accuracy: 0.7349\n",
            "Epoch 138/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3549 - accuracy: 0.9047 - val_loss: 2.4055 - val_accuracy: 0.7344\n",
            "Epoch 139/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3525 - accuracy: 0.9055 - val_loss: 2.4042 - val_accuracy: 0.7361\n",
            "Epoch 140/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3495 - accuracy: 0.9059 - val_loss: 2.4147 - val_accuracy: 0.7336\n",
            "Epoch 141/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3472 - accuracy: 0.9069 - val_loss: 2.4228 - val_accuracy: 0.7338\n",
            "Epoch 142/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3440 - accuracy: 0.9076 - val_loss: 2.4290 - val_accuracy: 0.7354\n",
            "Epoch 143/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3421 - accuracy: 0.9067 - val_loss: 2.4367 - val_accuracy: 0.7337\n",
            "Epoch 144/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3389 - accuracy: 0.9087 - val_loss: 2.4449 - val_accuracy: 0.7359\n",
            "Epoch 145/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3357 - accuracy: 0.9091 - val_loss: 2.4578 - val_accuracy: 0.7361\n",
            "Epoch 146/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3346 - accuracy: 0.9097 - val_loss: 2.4603 - val_accuracy: 0.7334\n",
            "Epoch 147/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3314 - accuracy: 0.9103 - val_loss: 2.4659 - val_accuracy: 0.7359\n",
            "Epoch 148/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3287 - accuracy: 0.9115 - val_loss: 2.4724 - val_accuracy: 0.7346\n",
            "Epoch 149/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3268 - accuracy: 0.9114 - val_loss: 2.4792 - val_accuracy: 0.7335\n",
            "Epoch 150/200\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.3236 - accuracy: 0.9127 - val_loss: 2.4896 - val_accuracy: 0.7329\n",
            "Epoch 151/200\n",
            "132/132 [==============================] - 3s 23ms/step - loss: 0.3211 - accuracy: 0.9136 - val_loss: 2.4935 - val_accuracy: 0.7319\n",
            "Epoch 152/200\n",
            "132/132 [==============================] - 3s 20ms/step - loss: 0.3186 - accuracy: 0.9142 - val_loss: 2.5016 - val_accuracy: 0.7334\n",
            "Epoch 153/200\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3170 - accuracy: 0.9141 - val_loss: 2.5033 - val_accuracy: 0.7334\n",
            "Epoch 154/200\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3137 - accuracy: 0.9155 - val_loss: 2.5163 - val_accuracy: 0.7331\n",
            "Epoch 155/200\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.3125 - accuracy: 0.9155 - val_loss: 2.5268 - val_accuracy: 0.7313\n",
            "Epoch 156/200\n",
            "132/132 [==============================] - 3s 21ms/step - loss: 0.3092 - accuracy: 0.9164 - val_loss: 2.5331 - val_accuracy: 0.7318\n",
            "Epoch 157/200\n",
            "132/132 [==============================] - 3s 25ms/step - loss: 0.3081 - accuracy: 0.9167 - val_loss: 2.5337 - val_accuracy: 0.7315\n",
            "Epoch 158/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.3064 - accuracy: 0.9180 - val_loss: 2.5468 - val_accuracy: 0.7330\n",
            "Epoch 159/200\n",
            "132/132 [==============================] - 3s 20ms/step - loss: 0.3031 - accuracy: 0.9178 - val_loss: 2.5535 - val_accuracy: 0.7323\n",
            "Epoch 160/200\n",
            "132/132 [==============================] - 3s 21ms/step - loss: 0.3020 - accuracy: 0.9181 - val_loss: 2.5591 - val_accuracy: 0.7349\n",
            "Epoch 161/200\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2996 - accuracy: 0.9191 - val_loss: 2.5570 - val_accuracy: 0.7316\n",
            "Epoch 162/200\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2973 - accuracy: 0.9184 - val_loss: 2.5839 - val_accuracy: 0.7329\n",
            "Epoch 163/200\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2943 - accuracy: 0.9195 - val_loss: 2.5717 - val_accuracy: 0.7313\n",
            "Epoch 164/200\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2933 - accuracy: 0.9199 - val_loss: 2.5839 - val_accuracy: 0.7316\n",
            "Epoch 165/200\n",
            "132/132 [==============================] - 3s 20ms/step - loss: 0.2912 - accuracy: 0.9209 - val_loss: 2.5982 - val_accuracy: 0.7319\n",
            "Epoch 166/200\n",
            "132/132 [==============================] - 3s 20ms/step - loss: 0.2890 - accuracy: 0.9216 - val_loss: 2.5976 - val_accuracy: 0.7319\n",
            "Epoch 167/200\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2874 - accuracy: 0.9215 - val_loss: 2.6060 - val_accuracy: 0.7329\n",
            "Epoch 168/200\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2854 - accuracy: 0.9219 - val_loss: 2.6111 - val_accuracy: 0.7292\n",
            "Epoch 169/200\n",
            "132/132 [==============================] - 3s 19ms/step - loss: 0.2846 - accuracy: 0.9217 - val_loss: 2.6266 - val_accuracy: 0.7312\n",
            "Epoch 170/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2834 - accuracy: 0.9224 - val_loss: 2.6265 - val_accuracy: 0.7304\n",
            "Epoch 171/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2807 - accuracy: 0.9232 - val_loss: 2.6385 - val_accuracy: 0.7307\n",
            "Epoch 172/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2789 - accuracy: 0.9236 - val_loss: 2.6297 - val_accuracy: 0.7304\n",
            "Epoch 173/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2769 - accuracy: 0.9242 - val_loss: 2.6471 - val_accuracy: 0.7315\n",
            "Epoch 174/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2750 - accuracy: 0.9242 - val_loss: 2.6535 - val_accuracy: 0.7299\n",
            "Epoch 175/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2732 - accuracy: 0.9250 - val_loss: 2.6621 - val_accuracy: 0.7318\n",
            "Epoch 176/200\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 0.2719 - accuracy: 0.9248 - val_loss: 2.6659 - val_accuracy: 0.7322\n",
            "Epoch 177/200\n",
            "132/132 [==============================] - 2s 19ms/step - loss: 0.2694 - accuracy: 0.9253 - val_loss: 2.6717 - val_accuracy: 0.7326\n",
            "Epoch 178/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2690 - accuracy: 0.9251 - val_loss: 2.6816 - val_accuracy: 0.7303\n",
            "Epoch 179/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2668 - accuracy: 0.9268 - val_loss: 2.6903 - val_accuracy: 0.7309\n",
            "Epoch 180/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2652 - accuracy: 0.9266 - val_loss: 2.6940 - val_accuracy: 0.7310\n",
            "Epoch 181/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2644 - accuracy: 0.9275 - val_loss: 2.7027 - val_accuracy: 0.7291\n",
            "Epoch 182/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2635 - accuracy: 0.9265 - val_loss: 2.7023 - val_accuracy: 0.7300\n",
            "Epoch 183/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2612 - accuracy: 0.9274 - val_loss: 2.7127 - val_accuracy: 0.7314\n",
            "Epoch 184/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2596 - accuracy: 0.9277 - val_loss: 2.7197 - val_accuracy: 0.7306\n",
            "Epoch 185/200\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.2588 - accuracy: 0.9282 - val_loss: 2.7212 - val_accuracy: 0.7291\n",
            "Epoch 186/200\n",
            "132/132 [==============================] - 2s 18ms/step - loss: 0.2567 - accuracy: 0.9287 - val_loss: 2.7332 - val_accuracy: 0.7295\n",
            "Epoch 187/200\n",
            "132/132 [==============================] - 2s 16ms/step - loss: 0.2556 - accuracy: 0.9283 - val_loss: 2.7348 - val_accuracy: 0.7298\n",
            "Epoch 188/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2541 - accuracy: 0.9283 - val_loss: 2.7400 - val_accuracy: 0.7312\n",
            "Epoch 189/200\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 0.2532 - accuracy: 0.9291 - val_loss: 2.7442 - val_accuracy: 0.7283\n",
            "Epoch 190/200\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 0.2520 - accuracy: 0.9299 - val_loss: 2.7554 - val_accuracy: 0.7297\n",
            "Epoch 191/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2506 - accuracy: 0.9298 - val_loss: 2.7595 - val_accuracy: 0.7308\n",
            "Epoch 192/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2489 - accuracy: 0.9301 - val_loss: 2.7682 - val_accuracy: 0.7297\n",
            "Epoch 193/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2487 - accuracy: 0.9304 - val_loss: 2.7744 - val_accuracy: 0.7282\n",
            "Epoch 194/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2477 - accuracy: 0.9300 - val_loss: 2.7826 - val_accuracy: 0.7309\n",
            "Epoch 195/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2463 - accuracy: 0.9302 - val_loss: 2.7813 - val_accuracy: 0.7285\n",
            "Epoch 196/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2455 - accuracy: 0.9304 - val_loss: 2.7903 - val_accuracy: 0.7275\n",
            "Epoch 197/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2435 - accuracy: 0.9311 - val_loss: 2.7961 - val_accuracy: 0.7275\n",
            "Epoch 198/200\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.2426 - accuracy: 0.9312 - val_loss: 2.8003 - val_accuracy: 0.7272\n",
            "Epoch 199/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2415 - accuracy: 0.9313 - val_loss: 2.8162 - val_accuracy: 0.7280\n",
            "Epoch 200/200\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.2405 - accuracy: 0.9317 - val_loss: 2.8114 - val_accuracy: 0.7265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='training')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='validation')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Ah5SWWIx4AGU",
        "outputId": "7797d333-7909-4bb5-b25d-11f747773ece"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia\n",
        "Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Armar los conversores de índice a palabra:\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}\n",
        "\n",
        "\n",
        "def get_answer_sentence(input_seq):\n",
        "    # Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n",
        "    # para enviar la primera vez al decoder\n",
        "    states_value = encoder_model.predict(input_seq,verbose=0)\n",
        "\n",
        "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "    # Se obtiene el índice que finaliza la inferencia\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "    \n",
        "    output_sentence = []\n",
        "    for _ in range(max_out_len):\n",
        "        # Predicción del próximo elemento\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value,verbose=0)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        # Si es \"end of sentece <eos>\" se acaba\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        # Transformar idx a palabra\n",
        "        word = ''        \n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        # Actualizar los estados dada la última predicción\n",
        "        states_value = [h, c]\n",
        "\n",
        "        # Actualizar secuencia de entrada con la salida (re-alimentación)\n",
        "        target_seq[0, 0] = idx\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ],
      "metadata": {
        "id": "e7HJNwHr1oXk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install gradio --quiet\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5IgMzwIJ3UR",
        "outputId": "d5700f51-1742-4c4e-a005-9e442c420c3d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 13.8 MB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 106 kB 80.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 67.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 278 kB 74.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.7 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    toke_input = input_tokenizer.texts_to_sequences([human_text])[0]\n",
        "    print(\"Q: \", human_text)   \n",
        "\n",
        "    # Si tienen distinto largo\n",
        "    encoder_sequence_test = pad_sequences([toke_input], maxlen=max_input_len)\n",
        "    \n",
        "    # Inferencia\n",
        "    out_word = get_answer_sentence(encoder_sequence_test)\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    response = ' ' + out_word\n",
        "    print(\"A:\", response)\n",
        "    return response\n",
        "    \n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\",\n",
        "    layout=\"vertical\")\n",
        "\n",
        "iface.launch(debug=True)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Eo780JPN66ja",
        "outputId": "cb69b1db-7a9f-4391-fd3e-488c3afa3d57"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `layout` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q:  hello!\n",
            "A:  hello how are you\n",
            "Q:  i'm well, and you?\n",
            "A:  i am a software engineer\n",
            "Q:  that is great! I also want to work in software\n",
            "A:  do you go to the movies\n",
            "Q:  sometimes, and you? \n",
            "A:  what do you do for a living\n",
            "Q:  I work at a tech company\n",
            "A:  how and why retired\n",
            "Q:  are you retired? \n",
            "A:  i love robotics\n",
            "Q:  which type of robotics?\n",
            "A:  i like to go to the beach\n",
            "Q:  beaches are nice...\n",
            "A:  what do you do for a living\n",
            "Q:  i work in customer service\n",
            "A:  it is a good thing\n",
            "Q:  thanks, you are very kind\n",
            "A:  i am not sure what you mean\n",
            "Q:  ok, good to talk with you guachin\n",
            "A:  i want to see the world\n",
            "Q:  too late for that lol\n",
            "A:  what are you up to today\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusiones\n",
        "\n",
        "Se pudo comprobar que las secuencias de respuesta dependían fuertemente de la cantidad de epochs de train que se hacían. COn una baja cantidad de epochs, se vio que la respuesta era una de dos \"i'm a girl\", \"i'm vegan\". La complejidad de las respuestas mejora cuando se emplean mas epochs.  \n",
        "\n",
        "Se comprueba que el modelo overfittea bastante groseramente, Se probó usar droput para mitigar el problema.  pero los resultados no fueron extremadamente mejores,  tal vez se obtendrian mejores resultados implementando el dropout conjuntamente con otras estrategias como max-norm de acuerdo a este paper \"Dropout: A Simple Way to Prevent Neural Networks from Overfitting \".\n",
        "\n",
        "La tecnica explorada de encoders/decoders es una herramienta interesante porque permite contextualizar un poco mejor que con LSTMs comunes. Sin embargo lo desafiante de esta situacion es emplear un modelo lo suficientemente poderoso y no overfiteador que de una idea mas profunda del contexto. "
      ],
      "metadata": {
        "id": "2Ni4-VbD1pQZ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}