{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esgoty/Elessanti/blob/main/Custom_embedding_with_Gensim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chandler and monica had diferent ways to speak.\n",
        "\n",
        "this example will obtain different embeddings representation of chandler and Monica's lines. \n",
        "\n",
        "The analysis allows us to 2 verify two interesting things.\n",
        "\n",
        "1. for starters, it allows us to obtain a numeric representation of words that is **context dependent** for training NLP models. \n",
        "\n",
        "2. but additionally, it allows us to analyze the differences in each character's narrative of the world. This is actually quite relevant nowadays because we are being exposed each day to hundreds of different takes on reality and some times, it's a cool thing to dissect the discourse and analyze it for a better grasp on things. "
      ],
      "metadata": {
        "id": "TAZdK5U6F92_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF23ASlC1eG1",
        "outputId": "0f910795-6a21-40ae-c5a1-a4b503251f5a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lFToQs5FK5uZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- Chandler lines"
      ],
      "metadata": {
        "id": "FQEx1LiQ4Y4M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07zJxG7H9vG"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ticoqYD1Z3I7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "9ffae068-c49d-48f6-aa94-4c234362439b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0\n",
              "0  all right joey, be nice.  so does he have a hu...\n",
              "1                          sounds like a date to me.\n",
              "2  alright, so i'm back in high school, i'm stand...\n",
              "3  then i look down, and i realize there's a phon...\n",
              "4                                      that's right."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e91ba11-8d3f-4717-93c3-a897a9150af8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>all right joey, be nice.  so does he have a hu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sounds like a date to me.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>alright, so i'm back in high school, i'm stand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>then i look down, and i realize there's a phon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>that's right.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e91ba11-8d3f-4717-93c3-a897a9150af8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e91ba11-8d3f-4717-93c3-a897a9150af8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e91ba11-8d3f-4717-93c3-a897a9150af8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Armar el dataset utilizando salto de línea para separar las oraciones/docs\n",
        "df_chandler = pd.read_csv('/content/drive/MyDrive/NLP/chandler_lines.txt', sep='/n', header=None)\n",
        "df_chandler.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LEpKubK9XzXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b036be40-b85e-46a6-91fc-49ca9332fb74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de documentos: 8410\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df_chandler.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab94qaFlrA1G"
      },
      "source": [
        "### 1 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rIsmMWmjrDHd"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "sentence_tokens = []\n",
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en una secuencia de palabras (esto podría realizarse con NLTK o spaCy también)\n",
        "for _, row in df_chandler[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CHepi_DGrbhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8476878a-1c25-47b6-9510-017dd23feda5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['all',\n",
              "  'right',\n",
              "  'joey',\n",
              "  'be',\n",
              "  'nice',\n",
              "  'so',\n",
              "  'does',\n",
              "  'he',\n",
              "  'have',\n",
              "  'a',\n",
              "  'hump',\n",
              "  'a',\n",
              "  'hump',\n",
              "  'and',\n",
              "  'a',\n",
              "  'hairpiece'],\n",
              " ['sounds', 'like', 'a', 'date', 'to', 'me']]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Demos un vistazo\n",
        "sentence_tokens[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaXV6nlHr5Aa"
      },
      "source": [
        "### 2 - Crear los vectores (word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OSb0v7h8r7hK"
      },
      "outputs": [],
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobracargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i0wnDdv9sJ47"
      },
      "outputs": [],
      "source": [
        "# Crearmos el modelo generador de vectoeres\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model_chandler = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     size=300,       # dimensionalidad de los vectores \n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1)           # modelo 0:CBOW  1:skipgram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5lTt8wErsf17"
      },
      "outputs": [],
      "source": [
        "# Buildear el vocabularui con los tokens\n",
        "w2v_model_chandler.build_vocab(sentence_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TNc9qt4os5AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57017d38-78be-4db1-ffe8-701e112ac596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 8410\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model_chandler.corpus_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "idw9cHF3tSMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb29a05-070e-4077-d27f-53dfdbb6b61f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de words distintas en el corpus: 1387\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model_chandler.wv.vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC9mZ8DPk-UC"
      },
      "source": [
        "### 3 - Entrenar el modelo generador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QSp-x0PAsq56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b212fcc0-508d-46a1-efc5-6bf305fd1650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 678863.4375\n",
            "Loss after epoch 1: 511033.5625\n",
            "Loss after epoch 2: 462405.875\n",
            "Loss after epoch 3: 454317.625\n",
            "Loss after epoch 4: 392148.5\n",
            "Loss after epoch 5: 393440.25\n",
            "Loss after epoch 6: 389980.0\n",
            "Loss after epoch 7: 387951.25\n",
            "Loss after epoch 8: 384967.0\n",
            "Loss after epoch 9: 367235.0\n",
            "Loss after epoch 10: 354563.5\n",
            "Loss after epoch 11: 354876.5\n",
            "Loss after epoch 12: 350866.5\n",
            "Loss after epoch 13: 350095.5\n",
            "Loss after epoch 14: 347371.0\n",
            "Loss after epoch 15: 345511.0\n",
            "Loss after epoch 16: 342778.5\n",
            "Loss after epoch 17: 341133.5\n",
            "Loss after epoch 18: 341465.0\n",
            "Loss after epoch 19: 336949.5\n",
            "Loss after epoch 20: 338422.0\n",
            "Loss after epoch 21: 326763.0\n",
            "Loss after epoch 22: 315408.0\n",
            "Loss after epoch 23: 314601.0\n",
            "Loss after epoch 24: 314962.0\n",
            "Loss after epoch 25: 310780.0\n",
            "Loss after epoch 26: 311309.0\n",
            "Loss after epoch 27: 311249.0\n",
            "Loss after epoch 28: 309831.0\n",
            "Loss after epoch 29: 307484.0\n",
            "Loss after epoch 30: 307929.0\n",
            "Loss after epoch 31: 307145.0\n",
            "Loss after epoch 32: 304429.0\n",
            "Loss after epoch 33: 306536.0\n",
            "Loss after epoch 34: 304485.0\n",
            "Loss after epoch 35: 303909.0\n",
            "Loss after epoch 36: 305720.0\n",
            "Loss after epoch 37: 304187.0\n",
            "Loss after epoch 38: 301619.0\n",
            "Loss after epoch 39: 302883.0\n",
            "Loss after epoch 40: 302584.0\n",
            "Loss after epoch 41: 302696.0\n",
            "Loss after epoch 42: 301355.0\n",
            "Loss after epoch 43: 301827.0\n",
            "Loss after epoch 44: 301810.0\n",
            "Loss after epoch 45: 299741.0\n",
            "Loss after epoch 46: 301888.0\n",
            "Loss after epoch 47: 299309.0\n",
            "Loss after epoch 48: 298768.0\n",
            "Loss after epoch 49: 279988.0\n",
            "Loss after epoch 50: 279892.0\n",
            "Loss after epoch 51: 279254.0\n",
            "Loss after epoch 52: 277092.0\n",
            "Loss after epoch 53: 278802.0\n",
            "Loss after epoch 54: 279514.0\n",
            "Loss after epoch 55: 279492.0\n",
            "Loss after epoch 56: 279798.0\n",
            "Loss after epoch 57: 277980.0\n",
            "Loss after epoch 58: 277690.0\n",
            "Loss after epoch 59: 278908.0\n",
            "Loss after epoch 60: 277608.0\n",
            "Loss after epoch 61: 277418.0\n",
            "Loss after epoch 62: 277668.0\n",
            "Loss after epoch 63: 277096.0\n",
            "Loss after epoch 64: 277434.0\n",
            "Loss after epoch 65: 276752.0\n",
            "Loss after epoch 66: 277312.0\n",
            "Loss after epoch 67: 275586.0\n",
            "Loss after epoch 68: 276052.0\n",
            "Loss after epoch 69: 275544.0\n",
            "Loss after epoch 70: 274706.0\n",
            "Loss after epoch 71: 274862.0\n",
            "Loss after epoch 72: 274036.0\n",
            "Loss after epoch 73: 274286.0\n",
            "Loss after epoch 74: 272628.0\n",
            "Loss after epoch 75: 272154.0\n",
            "Loss after epoch 76: 275022.0\n",
            "Loss after epoch 77: 274100.0\n",
            "Loss after epoch 78: 273064.0\n",
            "Loss after epoch 79: 272332.0\n",
            "Loss after epoch 80: 273476.0\n",
            "Loss after epoch 81: 272954.0\n",
            "Loss after epoch 82: 273770.0\n",
            "Loss after epoch 83: 272500.0\n",
            "Loss after epoch 84: 271766.0\n",
            "Loss after epoch 85: 272482.0\n",
            "Loss after epoch 86: 273084.0\n",
            "Loss after epoch 87: 271890.0\n",
            "Loss after epoch 88: 270412.0\n",
            "Loss after epoch 89: 272542.0\n",
            "Loss after epoch 90: 270092.0\n",
            "Loss after epoch 91: 273734.0\n",
            "Loss after epoch 92: 272420.0\n",
            "Loss after epoch 93: 271000.0\n",
            "Loss after epoch 94: 270360.0\n",
            "Loss after epoch 95: 271778.0\n",
            "Loss after epoch 96: 271910.0\n",
            "Loss after epoch 97: 270022.0\n",
            "Loss after epoch 98: 270206.0\n",
            "Loss after epoch 99: 268502.0\n",
            "Loss after epoch 100: 271314.0\n",
            "Loss after epoch 101: 269056.0\n",
            "Loss after epoch 102: 270078.0\n",
            "Loss after epoch 103: 268362.0\n",
            "Loss after epoch 104: 268582.0\n",
            "Loss after epoch 105: 269388.0\n",
            "Loss after epoch 106: 269146.0\n",
            "Loss after epoch 107: 268290.0\n",
            "Loss after epoch 108: 271104.0\n",
            "Loss after epoch 109: 268348.0\n",
            "Loss after epoch 110: 262524.0\n",
            "Loss after epoch 111: 260856.0\n",
            "Loss after epoch 112: 260780.0\n",
            "Loss after epoch 113: 259716.0\n",
            "Loss after epoch 114: 260568.0\n",
            "Loss after epoch 115: 261304.0\n",
            "Loss after epoch 116: 257444.0\n",
            "Loss after epoch 117: 260620.0\n",
            "Loss after epoch 118: 260828.0\n",
            "Loss after epoch 119: 259936.0\n",
            "Loss after epoch 120: 258052.0\n",
            "Loss after epoch 121: 259468.0\n",
            "Loss after epoch 122: 258308.0\n",
            "Loss after epoch 123: 256136.0\n",
            "Loss after epoch 124: 258456.0\n",
            "Loss after epoch 125: 256096.0\n",
            "Loss after epoch 126: 258316.0\n",
            "Loss after epoch 127: 256500.0\n",
            "Loss after epoch 128: 258432.0\n",
            "Loss after epoch 129: 255912.0\n",
            "Loss after epoch 130: 258768.0\n",
            "Loss after epoch 131: 255276.0\n",
            "Loss after epoch 132: 258836.0\n",
            "Loss after epoch 133: 255396.0\n",
            "Loss after epoch 134: 256620.0\n",
            "Loss after epoch 135: 258556.0\n",
            "Loss after epoch 136: 255300.0\n",
            "Loss after epoch 137: 254632.0\n",
            "Loss after epoch 138: 256752.0\n",
            "Loss after epoch 139: 253452.0\n",
            "Loss after epoch 140: 256156.0\n",
            "Loss after epoch 141: 254016.0\n",
            "Loss after epoch 142: 256592.0\n",
            "Loss after epoch 143: 253800.0\n",
            "Loss after epoch 144: 251760.0\n",
            "Loss after epoch 145: 252860.0\n",
            "Loss after epoch 146: 253860.0\n",
            "Loss after epoch 147: 251312.0\n",
            "Loss after epoch 148: 253024.0\n",
            "Loss after epoch 149: 252952.0\n",
            "Loss after epoch 150: 251992.0\n",
            "Loss after epoch 151: 253740.0\n",
            "Loss after epoch 152: 251000.0\n",
            "Loss after epoch 153: 252816.0\n",
            "Loss after epoch 154: 252120.0\n",
            "Loss after epoch 155: 252504.0\n",
            "Loss after epoch 156: 250508.0\n",
            "Loss after epoch 157: 249912.0\n",
            "Loss after epoch 158: 250184.0\n",
            "Loss after epoch 159: 251260.0\n",
            "Loss after epoch 160: 249428.0\n",
            "Loss after epoch 161: 253152.0\n",
            "Loss after epoch 162: 249044.0\n",
            "Loss after epoch 163: 250128.0\n",
            "Loss after epoch 164: 249592.0\n",
            "Loss after epoch 165: 248732.0\n",
            "Loss after epoch 166: 248820.0\n",
            "Loss after epoch 167: 248692.0\n",
            "Loss after epoch 168: 247812.0\n",
            "Loss after epoch 169: 246748.0\n",
            "Loss after epoch 170: 247644.0\n",
            "Loss after epoch 171: 246476.0\n",
            "Loss after epoch 172: 248312.0\n",
            "Loss after epoch 173: 245520.0\n",
            "Loss after epoch 174: 246812.0\n",
            "Loss after epoch 175: 246752.0\n",
            "Loss after epoch 176: 248056.0\n",
            "Loss after epoch 177: 247124.0\n",
            "Loss after epoch 178: 245040.0\n",
            "Loss after epoch 179: 246108.0\n",
            "Loss after epoch 180: 243788.0\n",
            "Loss after epoch 181: 245964.0\n",
            "Loss after epoch 182: 243748.0\n",
            "Loss after epoch 183: 244736.0\n",
            "Loss after epoch 184: 245872.0\n",
            "Loss after epoch 185: 245068.0\n",
            "Loss after epoch 186: 246200.0\n",
            "Loss after epoch 187: 245336.0\n",
            "Loss after epoch 188: 245108.0\n",
            "Loss after epoch 189: 242996.0\n",
            "Loss after epoch 190: 244852.0\n",
            "Loss after epoch 191: 245360.0\n",
            "Loss after epoch 192: 246012.0\n",
            "Loss after epoch 193: 245276.0\n",
            "Loss after epoch 194: 243420.0\n",
            "Loss after epoch 195: 241728.0\n",
            "Loss after epoch 196: 243032.0\n",
            "Loss after epoch 197: 243320.0\n",
            "Loss after epoch 198: 243120.0\n",
            "Loss after epoch 199: 241784.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10715062, 17262600)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model_chandler.train(sentence_tokens,\n",
        "                 total_examples=w2v_model_chandler.corpus_count,\n",
        "                 epochs=200,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddT9NVuNlCAe"
      },
      "source": [
        "### 4 - Ensayar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6cHN9xGLuPEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10910c5a-759c-4b43-c818-f17a9fd3b569"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ehh', 0.332955926656723),\n",
              " ('dinner', 0.31776440143585205),\n",
              " ('bowl', 0.2836850881576538),\n",
              " ('catch', 0.2779606282711029),\n",
              " ('steal', 0.27760791778564453),\n",
              " ('screaming', 0.26454854011535645),\n",
              " ('helen', 0.26332029700279236),\n",
              " ('ugly', 0.2630704343318939),\n",
              " ('control', 0.26277899742126465),\n",
              " ('10', 0.26168137788772583)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model_chandler.wv.most_similar(positive=[\"work\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "47HiU5gdkdMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792a3df5-3953-4872-b816-0e20d4d26d49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lights', 0.04228873550891876),\n",
              " ('nobody', 0.041226353496313095),\n",
              " ('plane', 0.039347097277641296),\n",
              " ('special', 0.039189413189888),\n",
              " ('straight', 0.039126597344875336),\n",
              " ('plan', 0.028084486722946167),\n",
              " ('hug', 0.02706683985888958),\n",
              " ('wonder', 0.026550067588686943),\n",
              " ('picture', 0.025340469554066658),\n",
              " ('stage', 0.025141429156064987)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model_chandler.wv.most_similar(negative=[\"love\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DT4Rvno2mD65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e11c928-364a-4df2-9965-de7216b794b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('keys', 0.34803348779678345),\n",
              " ('borrow', 0.3285517692565918),\n",
              " ('days', 0.32529890537261963),\n",
              " ('foosball', 0.306495726108551),\n",
              " ('hurt', 0.295035719871521),\n",
              " ('shorts', 0.2921173572540283),\n",
              " ('birds', 0.2906684875488281),\n",
              " ('thoughts', 0.28386127948760986),\n",
              " ('known', 0.28331488370895386),\n",
              " ('mike', 0.2814350128173828)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model_chandler.wv.most_similar(positive=[\"money\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XPLDPgzBmQXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567646cc-ddb8-4067-a0a0-491bd79b9d0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('glasses', 0.37916386127471924),\n",
              " ('stripper', 0.35650432109832764),\n",
              " ('watched', 0.3530530333518982),\n",
              " ('rabbit', 0.3492811918258667),\n",
              " ('college', 0.3489832580089569)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model_chandler.wv.most_similar(positive=[\"duck\"], topn=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g8UVWe6lFmh"
      },
      "source": [
        "### 5 - Visualizar agrupación de vectores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pDxEVXAivjr9"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import IncrementalPCA    \n",
        "from sklearn.manifold import TSNE                   \n",
        "import numpy as np                                  \n",
        "\n",
        "def reduce_dimensions(model):\n",
        "    num_dimensions = 2  \n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index2word)  \n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    x_vals = [v[0] for v in vectors]\n",
        "    y_vals = [v[1] for v in vectors]\n",
        "    return x_vals, y_vals, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- Monica lines"
      ],
      "metadata": {
        "id": "xeHd-LR84h_f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaFYcnZG4h_g"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "961e8906-665d-46dd-8da6-e3bd83e09193",
        "id": "4DzD18bI4h_i"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0\n",
              "0  there's nothing to tell! he's just some guy i ...\n",
              "1  okay, everybody relax. this is not even a date...\n",
              "2           and they weren't looking at you before?!\n",
              "3                             are you okay, sweetie?\n",
              "4                   carol moved her stuff out today."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ca31608-9648-4fa5-88e3-f742b4560e97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>there's nothing to tell! he's just some guy i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>okay, everybody relax. this is not even a date...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>and they weren't looking at you before?!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>are you okay, sweetie?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>carol moved her stuff out today.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ca31608-9648-4fa5-88e3-f742b4560e97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ca31608-9648-4fa5-88e3-f742b4560e97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ca31608-9648-4fa5-88e3-f742b4560e97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Armar el dataset utilizando salto de línea para separar las oraciones/docs\n",
        "df_monica = pd.read_csv('/content/drive/MyDrive/NLP/monica_lines.txt', sep='/n', header=None, engine='python',encoding='latin1')\n",
        "df_monica.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a2fb00-2b12-4f52-ac6c-06a333820326",
        "id": "m4Fnlypq4h_j"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de documentos: 8383\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df_monica.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPiyXsU-4h_k"
      },
      "source": [
        "### 1 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iBA_Ceib4h_l"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "sentence_tokens = []\n",
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en una secuencia de palabras (esto podría realizarse con NLTK o spaCy también)\n",
        "for _, row in df_monica[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf53215-83cb-4404-aeb5-8d921467d51e",
        "id": "S5cXTTt04h_m"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"there's\",\n",
              "  'nothing',\n",
              "  'to',\n",
              "  'tell',\n",
              "  \"he's\",\n",
              "  'just',\n",
              "  'some',\n",
              "  'guy',\n",
              "  'i',\n",
              "  'work',\n",
              "  'with'],\n",
              " ['okay',\n",
              "  'everybody',\n",
              "  'relax',\n",
              "  'this',\n",
              "  'is',\n",
              "  'not',\n",
              "  'even',\n",
              "  'a',\n",
              "  'date',\n",
              "  \"it's\",\n",
              "  'just',\n",
              "  'two',\n",
              "  'people',\n",
              "  'going',\n",
              "  'out',\n",
              "  'to',\n",
              "  'dinner',\n",
              "  'and',\n",
              "  'not',\n",
              "  'having',\n",
              "  'sex']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Demos un vistazo\n",
        "sentence_tokens[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlFdaSgF4h_m"
      },
      "source": [
        "### 2 - Crear los vectores (word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0MUgD70L4h_n"
      },
      "outputs": [],
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobracargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1DF-maaK4h_o"
      },
      "outputs": [],
      "source": [
        "# Crearmos el modelo generador de vectoeres\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model_monica = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     size=300,       # dimensionalidad de los vectores \n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1)           # modelo 0:CBOW  1:skipgram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OWe6NqsO4h_p"
      },
      "outputs": [],
      "source": [
        "# Buildear el vocabularui con los tokens\n",
        "w2v_model_monica.build_vocab(sentence_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51af59a-ef59-430a-8ca3-684f5ea76d32",
        "id": "FONr_UgQ4h_q"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 8383\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model_monica.corpus_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b93353b0-2882-402f-8c18-b6943b665aac",
        "id": "kWWcY0sh4h_q"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de words distintas en el corpus: 1267\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model_monica.wv.vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsUXFD5t4h_s"
      },
      "source": [
        "### 3 - Entrenar el modelo generador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7356b0-08cd-42a1-8555-cb4b3627b026",
        "id": "v60aYDke4h_s"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 648995.8125\n",
            "Loss after epoch 1: 497137.3125\n",
            "Loss after epoch 2: 442592.375\n",
            "Loss after epoch 3: 436279.25\n",
            "Loss after epoch 4: 385107.0\n",
            "Loss after epoch 5: 375773.5\n",
            "Loss after epoch 6: 370131.25\n",
            "Loss after epoch 7: 371749.75\n",
            "Loss after epoch 8: 368518.5\n",
            "Loss after epoch 9: 362432.25\n",
            "Loss after epoch 10: 340832.5\n",
            "Loss after epoch 11: 340091.0\n",
            "Loss after epoch 12: 336866.0\n",
            "Loss after epoch 13: 337625.0\n",
            "Loss after epoch 14: 335365.5\n",
            "Loss after epoch 15: 332665.0\n",
            "Loss after epoch 16: 330636.5\n",
            "Loss after epoch 17: 328696.5\n",
            "Loss after epoch 18: 327106.5\n",
            "Loss after epoch 19: 326918.0\n",
            "Loss after epoch 20: 325221.5\n",
            "Loss after epoch 21: 324405.0\n",
            "Loss after epoch 22: 311759.0\n",
            "Loss after epoch 23: 302875.0\n",
            "Loss after epoch 24: 303908.0\n",
            "Loss after epoch 25: 300556.0\n",
            "Loss after epoch 26: 301433.0\n",
            "Loss after epoch 27: 300424.0\n",
            "Loss after epoch 28: 299931.0\n",
            "Loss after epoch 29: 298948.0\n",
            "Loss after epoch 30: 297471.0\n",
            "Loss after epoch 31: 297955.0\n",
            "Loss after epoch 32: 296128.0\n",
            "Loss after epoch 33: 295333.0\n",
            "Loss after epoch 34: 295355.0\n",
            "Loss after epoch 35: 294539.0\n",
            "Loss after epoch 36: 295179.0\n",
            "Loss after epoch 37: 294032.0\n",
            "Loss after epoch 38: 294012.0\n",
            "Loss after epoch 39: 294891.0\n",
            "Loss after epoch 40: 292297.0\n",
            "Loss after epoch 41: 292514.0\n",
            "Loss after epoch 42: 293552.0\n",
            "Loss after epoch 43: 292490.0\n",
            "Loss after epoch 44: 292193.0\n",
            "Loss after epoch 45: 293636.0\n",
            "Loss after epoch 46: 290460.0\n",
            "Loss after epoch 47: 291196.0\n",
            "Loss after epoch 48: 290768.0\n",
            "Loss after epoch 49: 289771.0\n",
            "Loss after epoch 50: 287918.0\n",
            "Loss after epoch 51: 273468.0\n",
            "Loss after epoch 52: 272220.0\n",
            "Loss after epoch 53: 271518.0\n",
            "Loss after epoch 54: 270128.0\n",
            "Loss after epoch 55: 269760.0\n",
            "Loss after epoch 56: 271276.0\n",
            "Loss after epoch 57: 270912.0\n",
            "Loss after epoch 58: 271022.0\n",
            "Loss after epoch 59: 269110.0\n",
            "Loss after epoch 60: 268754.0\n",
            "Loss after epoch 61: 268734.0\n",
            "Loss after epoch 62: 269786.0\n",
            "Loss after epoch 63: 269742.0\n",
            "Loss after epoch 64: 270338.0\n",
            "Loss after epoch 65: 268390.0\n",
            "Loss after epoch 66: 269400.0\n",
            "Loss after epoch 67: 268306.0\n",
            "Loss after epoch 68: 269454.0\n",
            "Loss after epoch 69: 267774.0\n",
            "Loss after epoch 70: 268226.0\n",
            "Loss after epoch 71: 266202.0\n",
            "Loss after epoch 72: 266864.0\n",
            "Loss after epoch 73: 267866.0\n",
            "Loss after epoch 74: 268788.0\n",
            "Loss after epoch 75: 265574.0\n",
            "Loss after epoch 76: 267094.0\n",
            "Loss after epoch 77: 266318.0\n",
            "Loss after epoch 78: 264686.0\n",
            "Loss after epoch 79: 267600.0\n",
            "Loss after epoch 80: 265452.0\n",
            "Loss after epoch 81: 264620.0\n",
            "Loss after epoch 82: 265560.0\n",
            "Loss after epoch 83: 264898.0\n",
            "Loss after epoch 84: 265660.0\n",
            "Loss after epoch 85: 264458.0\n",
            "Loss after epoch 86: 264694.0\n",
            "Loss after epoch 87: 265122.0\n",
            "Loss after epoch 88: 265624.0\n",
            "Loss after epoch 89: 264626.0\n",
            "Loss after epoch 90: 264584.0\n",
            "Loss after epoch 91: 264640.0\n",
            "Loss after epoch 92: 264136.0\n",
            "Loss after epoch 93: 262862.0\n",
            "Loss after epoch 94: 264502.0\n",
            "Loss after epoch 95: 263634.0\n",
            "Loss after epoch 96: 261690.0\n",
            "Loss after epoch 97: 261840.0\n",
            "Loss after epoch 98: 263316.0\n",
            "Loss after epoch 99: 263398.0\n",
            "Loss after epoch 100: 263748.0\n",
            "Loss after epoch 101: 263216.0\n",
            "Loss after epoch 102: 261108.0\n",
            "Loss after epoch 103: 261512.0\n",
            "Loss after epoch 104: 262750.0\n",
            "Loss after epoch 105: 263796.0\n",
            "Loss after epoch 106: 262198.0\n",
            "Loss after epoch 107: 261636.0\n",
            "Loss after epoch 108: 263242.0\n",
            "Loss after epoch 109: 260276.0\n",
            "Loss after epoch 110: 261738.0\n",
            "Loss after epoch 111: 260264.0\n",
            "Loss after epoch 112: 261520.0\n",
            "Loss after epoch 113: 262352.0\n",
            "Loss after epoch 114: 255108.0\n",
            "Loss after epoch 115: 253072.0\n",
            "Loss after epoch 116: 253008.0\n",
            "Loss after epoch 117: 255872.0\n",
            "Loss after epoch 118: 254844.0\n",
            "Loss after epoch 119: 255292.0\n",
            "Loss after epoch 120: 255512.0\n",
            "Loss after epoch 121: 252604.0\n",
            "Loss after epoch 122: 256432.0\n",
            "Loss after epoch 123: 252928.0\n",
            "Loss after epoch 124: 250920.0\n",
            "Loss after epoch 125: 255864.0\n",
            "Loss after epoch 126: 253220.0\n",
            "Loss after epoch 127: 253052.0\n",
            "Loss after epoch 128: 251792.0\n",
            "Loss after epoch 129: 252888.0\n",
            "Loss after epoch 130: 252380.0\n",
            "Loss after epoch 131: 251736.0\n",
            "Loss after epoch 132: 252992.0\n",
            "Loss after epoch 133: 252500.0\n",
            "Loss after epoch 134: 251896.0\n",
            "Loss after epoch 135: 248344.0\n",
            "Loss after epoch 136: 251108.0\n",
            "Loss after epoch 137: 251804.0\n",
            "Loss after epoch 138: 252560.0\n",
            "Loss after epoch 139: 251112.0\n",
            "Loss after epoch 140: 250496.0\n",
            "Loss after epoch 141: 250220.0\n",
            "Loss after epoch 142: 249744.0\n",
            "Loss after epoch 143: 251860.0\n",
            "Loss after epoch 144: 250928.0\n",
            "Loss after epoch 145: 248200.0\n",
            "Loss after epoch 146: 248620.0\n",
            "Loss after epoch 147: 248624.0\n",
            "Loss after epoch 148: 250116.0\n",
            "Loss after epoch 149: 249364.0\n",
            "Loss after epoch 150: 248988.0\n",
            "Loss after epoch 151: 246864.0\n",
            "Loss after epoch 152: 248448.0\n",
            "Loss after epoch 153: 248060.0\n",
            "Loss after epoch 154: 248256.0\n",
            "Loss after epoch 155: 245680.0\n",
            "Loss after epoch 156: 246148.0\n",
            "Loss after epoch 157: 245792.0\n",
            "Loss after epoch 158: 243680.0\n",
            "Loss after epoch 159: 246416.0\n",
            "Loss after epoch 160: 246740.0\n",
            "Loss after epoch 161: 246528.0\n",
            "Loss after epoch 162: 244364.0\n",
            "Loss after epoch 163: 244992.0\n",
            "Loss after epoch 164: 244096.0\n",
            "Loss after epoch 165: 245524.0\n",
            "Loss after epoch 166: 247428.0\n",
            "Loss after epoch 167: 246832.0\n",
            "Loss after epoch 168: 246060.0\n",
            "Loss after epoch 169: 245680.0\n",
            "Loss after epoch 170: 246020.0\n",
            "Loss after epoch 171: 242556.0\n",
            "Loss after epoch 172: 242956.0\n",
            "Loss after epoch 173: 242552.0\n",
            "Loss after epoch 174: 244200.0\n",
            "Loss after epoch 175: 242920.0\n",
            "Loss after epoch 176: 241628.0\n",
            "Loss after epoch 177: 241716.0\n",
            "Loss after epoch 178: 243016.0\n",
            "Loss after epoch 179: 242636.0\n",
            "Loss after epoch 180: 240416.0\n",
            "Loss after epoch 181: 241188.0\n",
            "Loss after epoch 182: 240084.0\n",
            "Loss after epoch 183: 239544.0\n",
            "Loss after epoch 184: 242288.0\n",
            "Loss after epoch 185: 240896.0\n",
            "Loss after epoch 186: 242340.0\n",
            "Loss after epoch 187: 240936.0\n",
            "Loss after epoch 188: 239848.0\n",
            "Loss after epoch 189: 239796.0\n",
            "Loss after epoch 190: 237868.0\n",
            "Loss after epoch 191: 239892.0\n",
            "Loss after epoch 192: 238064.0\n",
            "Loss after epoch 193: 239604.0\n",
            "Loss after epoch 194: 238652.0\n",
            "Loss after epoch 195: 240224.0\n",
            "Loss after epoch 196: 238576.0\n",
            "Loss after epoch 197: 238616.0\n",
            "Loss after epoch 198: 238172.0\n",
            "Loss after epoch 199: 236932.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10339145, 16586600)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model_monica.train(sentence_tokens,\n",
        "                 total_examples=w2v_model_monica.corpus_count,\n",
        "                 epochs=200,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwwpuqZc4h_s"
      },
      "source": [
        "### 4 - Ensayar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754d49f6-240c-448c-a503-e5142bc99924",
        "id": "RU5TFnkw4h_s"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('clear', 0.31303489208221436),\n",
              " ('hospital', 0.30162501335144043),\n",
              " ('geoffrey', 0.3004313111305237),\n",
              " ('pizza', 0.29335469007492065),\n",
              " ('bank', 0.2863214910030365),\n",
              " ('van', 0.28570854663848877),\n",
              " ('nope', 0.28195327520370483),\n",
              " ('dinner', 0.2776287794113159),\n",
              " ('die', 0.2746597230434418),\n",
              " ('business', 0.2741873562335968)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model_monica.wv.most_similar(positive=[\"work\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ae464a-70f0-40eb-8924-a933532465f0",
        "id": "FIvsvUB84h_t"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('apparently', 0.04466196149587631),\n",
              " ('took', 0.04278826713562012),\n",
              " ('ago', 0.04198911413550377),\n",
              " ('does', 0.041572995483875275),\n",
              " (\"we've\", 0.04048974812030792),\n",
              " ('point', 0.035859186202287674),\n",
              " ('hundred', 0.025472812354564667),\n",
              " ('breasts', 0.023149803280830383),\n",
              " ('christmas', 0.020376067608594894),\n",
              " ('first', 0.019811401143670082)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model_monica.wv.most_similar(negative=[\"love\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ec5375-4ce5-4b12-a07f-13162c875309",
        "id": "mk1UyaCh4h_t"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('porn', 0.3444075882434845),\n",
              " ('soul', 0.33752816915512085),\n",
              " ('cookies', 0.3362638056278229),\n",
              " ('memories', 0.3276340663433075),\n",
              " ('lives', 0.32325267791748047),\n",
              " ('decision', 0.31753724813461304),\n",
              " ('van', 0.31297868490219116),\n",
              " ('children', 0.308643102645874),\n",
              " ('stole', 0.3045380115509033),\n",
              " ('candles', 0.3041505813598633)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model_monica.wv.most_similar(positive=[\"money\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac65879-8288-443b-ceee-83da8f19d9cc",
        "id": "Ahr5_LaO4h_u"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('realized', 0.3678734302520752),\n",
              " ('opened', 0.3592709004878998),\n",
              " ('places', 0.33507323265075684),\n",
              " ('wondering', 0.33321452140808105),\n",
              " ('keeping', 0.33035358786582947)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model_monica.wv.most_similar(positive=[\"clean\"], topn=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFU4A6Ft4h_u"
      },
      "source": [
        "### 5 - Visualizar agrupación de vectores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0kFRYaYr4h_v"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import IncrementalPCA    \n",
        "from sklearn.manifold import TSNE                   \n",
        "import numpy as np                                  \n",
        "\n",
        "def reduce_dimensions(model):\n",
        "    num_dimensions = 2  \n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index2word)  \n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    x_vals = [v[0] for v in vectors]\n",
        "    y_vals = [v[1] for v in vectors]\n",
        "    return x_vals, y_vals, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ploting embedings in 2d"
      ],
      "metadata": {
        "id": "Ae9-U7RR99u9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# monica emmbedings"
      ],
      "metadata": {
        "id": "quitb-rx-RYV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "53f179df-c119-4953-c79a-257c14e370db",
        "id": "jtKjJeU94h_v"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"8ca73e3e-3e0a-45c2-8622-43d4d3793521\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8ca73e3e-3e0a-45c2-8622-43d4d3793521\")) {                    Plotly.newPlot(                        \"8ca73e3e-3e0a-45c2-8622-43d4d3793521\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>text=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"you\",\"i\",\"the\",\"to\",\"a\",\"and\",\"it\",\"that\",\"what\",\"oh\",\"is\",\"this\",\"my\",\"so\",\"just\",\"me\",\"we\",\"okay\",\"do\",\"have\",\"no\",\"in\",\"of\",\"not\",\"are\",\"know\",\"with\",\"be\",\"on\",\"for\",\"all\",\"was\",\"right\",\"gonna\",\"your\",\"hey\",\"well\",\"yeah\",\"but\",\"get\",\"go\",\"really\",\"about\",\"i\\u00e2\\u0080\\u0099m\",\"i'm\",\"out\",\"like\",\"think\",\"if\",\"can\",\"mean\",\"god\",\"at\",\"it's\",\"how\",\"he\",\"here\",\"don't\",\"up\",\"did\",\"chandler\",\"don\\u00e2\\u0080\\u0099t\",\"it\\u00e2\\u0080\\u0099s\",\"why\",\"want\",\"now\",\"her\",\"one\",\"phoebe\",\"she\",\"got\",\"him\",\"come\",\"see\",\"going\",\"joey\",\"there\",\"look\",\"you're\",\"you\\u00e2\\u0080\\u0099re\",\"good\",\"would\",\"they\",\"rachel\",\"ross\",\"wait\",\"when\",\"sorry\",\"tell\",\"umm\",\"little\",\"were\",\"them\",\"time\",\"guys\",\"that\\u00e2\\u0080\\u0099s\",\"love\",\"could\",\"because\",\"that's\",\"hi\",\"great\",\"say\",\"something\",\"some\",\"then\",\"uh\",\"who\",\"doing\",\"ok\",\"make\",\"back\",\"too\",\"yes\",\"had\",\"guy\",\"maybe\",\"wanna\",\"y\\u00e2\\u0080\\u0099know\",\"us\",\"can\\u00e2\\u0080\\u0099t\",\"over\",\"our\",\"will\",\"baby\",\"been\",\"take\",\"can't\",\"as\",\"much\",\"an\",\"work\",\"believe\",\"way\",\"honey\",\"am\",\"from\",\"or\",\"we're\",\"y'know\",\"thing\",\"give\",\"we\\u00e2\\u0080\\u0099re\",\"thought\",\"even\",\"please\",\"still\",\"never\",\"wow\",\"should\",\"he's\",\"where\",\"need\",\"said\",\"people\",\"down\",\"let\",\"his\",\"again\",\"more\",\"i'll\",\"has\",\"thank\",\"two\",\"big\",\"only\",\"um\",\"call\",\"fine\",\"these\",\"i\\u00e2\\u0080\\u0099ll\",\"he\\u00e2\\u0080\\u0099s\",\"by\",\"first\",\"wedding\",\"does\",\"nothing\",\"sure\",\"stuff\",\"made\",\"huh\",\"dad\",\"alright\",\"anything\",\"rach\",\"off\",\"feel\",\"other\",\"she's\",\"stop\",\"talk\",\"put\",\"getting\",\"minute\",\"new\",\"nice\",\"ever\",\"didn't\",\"told\",\"didn\\u00e2\\u0080\\u0099t\"],\"x\":[4.590444087982178,5.318853855133057,-6.294206619262695,-2.5693886280059814,-7.127740383148193,-3.913917064666748,5.547391891479492,7.206015110015869,8.435240745544434,9.3419771194458,6.61590051651001,2.047693967819214,-8.442342758178711,17.60395050048828,4.040332794189453,2.2903144359588623,3.0067551136016846,5.636168956756592,6.314909934997559,-0.9007052779197693,7.0663981437683105,-5.879345893859863,-8.074195861816406,9.758484840393066,9.225356101989746,10.637979507446289,-3.012052059173584,2.0644314289093018,-7.1730852127075195,-3.575477123260498,-1.2476283311843872,13.247003555297852,0.24217776954174042,5.701618671417236,-6.9752326011657715,13.660449028015137,6.7761383056640625,15.39614486694336,8.549017906188965,-1.8867055177688599,-9.321446418762207,17.479400634765625,12.580739974975586,-0.7563502192497253,8.343379020690918,-4.6109466552734375,3.3731369972229004,10.886506080627441,7.717414379119873,-4.424979209899902,1.8230942487716675,8.066155433654785,-10.656174659729004,12.694321632385254,4.6697869300842285,4.364352703094482,0.6622012853622437,9.856410026550293,-9.128344535827637,3.801628589630127,6.4903435707092285,15.103342056274414,0.9554250836372375,9.554658889770508,-12.599135398864746,4.22623872756958,-9.251971244812012,-5.983609199523926,3.8185653686523438,1.0842307806015015,-26.50778579711914,1.2463313341140747,5.350388526916504,2.7194647789001465,11.295475006103516,2.7446866035461426,5.2955756187438965,10.131352424621582,23.574533462524414,3.6319265365600586,20.483749389648438,16.063480377197266,-0.05633567273616791,6.426575660705566,11.784852027893066,19.208669662475586,27.147188186645508,21.349018096923828,22.527685165405273,8.919629096984863,-7.570509910583496,11.862648963928223,-36.875850677490234,-10.451519012451172,-9.201138496398926,7.788181781768799,20.280155181884766,18.55077362060547,15.784208297729492,25.60212516784668,19.09238052368164,34.687286376953125,18.248788833618164,23.584360122680664,-50.07282257080078,-14.210938453674316,9.96422290802002,34.91366195678711,15.599257469177246,52.11398696899414,-14.68295955657959,-7.3560709953308105,32.28984451293945,47.780731201171875,-56.460628509521484,-5.721072196960449,20.59662628173828,13.518176078796387,29.931507110595703,-41.92795944213867,18.3382511138916,4.523254871368408,-61.25790786743164,20.829992294311523,-68.0806655883789,-58.660186767578125,8.100834846496582,0.6677796840667725,-30.602821350097656,41.96319580078125,-17.31247901916504,43.15724563598633,16.271425247192383,18.703523635864258,-8.753169059753418,-10.868788719177246,72.54193878173828,67.39053344726562,23.45783042907715,57.526493072509766,13.19915771484375,-28.189748764038086,-36.425567626953125,39.20901107788086,69.85364532470703,-7.910337448120117,60.467979431152344,70.04377746582031,51.116390228271484,24.421586990356445,62.92448043823242,11.958343505859375,-46.10541915893555,36.12702941894531,63.20815658569336,-37.13798522949219,18.940637588500977,4.972188472747803,49.19204330444336,80.51629638671875,18.97140884399414,21.307939529418945,51.5530891418457,-38.81859588623047,-64.1962890625,65.1484146118164,38.19987106323242,64.63416290283203,58.427406311035156,-70.2998275756836,19.088268280029297,69.1279067993164,-70.41861724853516,-5.392583847045898,-63.29783630371094,39.57514572143555,54.05668640136719,59.39690399169922,74.66891479492188,80.20941925048828,76.44142150878906,55.37697982788086,29.887126922607422,78.58216857910156,48.601165771484375,-40.68695068359375,45.58203887939453,65.18403625488281,68.04432678222656,10.287246704101562,28.024803161621094,-51.32770919799805,33.4280891418457,21.273466110229492,-56.944061279296875,64.7288818359375,73.34432220458984,32.743507385253906,36.200653076171875,20.544958114624023],\"xaxis\":\"x\",\"y\":[-2.3738675117492676,0.7206241488456726,3.028876543045044,-3.61299467086792,8.889755249023438,2.003676652908325,-0.7904607653617859,-0.5259416103363037,-2.513166666030884,15.179139137268066,5.002708435058594,1.2443599700927734,7.374011993408203,3.2658557891845703,-0.8331324458122253,-0.4785841703414917,-2.272620916366577,-3.633254051208496,-7.308023452758789,-2.319647789001465,3.0236976146698,1.1164664030075073,2.509546995162964,-4.32197904586792,-23.672285079956055,-0.020093372091650963,-1.813580870628357,-7.722558975219727,-1.9382820129394531,0.07207424938678741,-0.19110752642154694,13.687479019165039,-0.13434617221355438,-10.379820823669434,4.990823268890381,8.033074378967285,1.121914267539978,6.335554599761963,0.9949343204498291,-5.400522232055664,-16.082019805908203,-0.11159020662307739,-5.769410133361816,-13.754977226257324,-6.261683940887451,-3.087815761566162,6.433825492858887,2.017188310623169,-3.964712381362915,-5.282280921936035,-3.7513480186462402,15.756540298461914,2.4027187824249268,0.5110347867012024,-5.599580764770508,4.621127605438232,-5.924152851104736,-19.14427375793457,-7.85890007019043,0.9777779579162598,-5.265865802764893,-23.25755500793457,-9.676153182983398,-8.372145652770996,-6.690199375152588,-7.550534248352051,4.810152053833008,14.328934669494629,-3.857375144958496,-1.9290093183517456,-15.270730018615723,11.99467658996582,-25.539474487304688,-11.37722396850586,-10.285078048706055,-5.624792575836182,2.581954002380371,6.3369364738464355,-28.96461296081543,-9.572918891906738,6.59652042388916,-18.42952537536621,-4.021876811981201,-2.1948330402374268,-3.839367628097534,-12.566733360290527,-10.853325843811035,0.7766079902648926,-17.477256774902344,-0.8178855180740356,12.141302108764648,-26.798145294189453,-12.593549728393555,-0.0076048001646995544,-28.155017852783203,6.982270240783691,-3.5713257789611816,-23.866207122802734,9.220104217529297,16.076671600341797,15.053238868713379,8.864869117736816,-5.070870876312256,-21.060792922973633,-18.521522521972656,-45.50879669189453,10.939713478088379,38.45995330810547,-41.289337158203125,-61.00981140136719,-17.2897891998291,-49.474727630615234,16.940473556518555,21.783649444580078,11.44378662109375,17.12520980834961,38.15889358520508,-54.89467239379883,0.25388553738594055,47.28422927856445,-34.5353889465332,-41.63672637939453,41.26472473144531,-37.17554473876953,42.39045333862305,-30.67428970336914,-42.9206428527832,-40.509151458740234,-43.89540481567383,3.9981420040130615,71.76951599121094,-29.4456844329834,14.340435028076172,20.325469970703125,-34.91041946411133,-38.20277404785156,36.721038818359375,44.08964538574219,-34.5067024230957,-33.770774841308594,59.5792350769043,-28.623638153076172,-33.92356872558594,13.222846031188965,-6.25985050201416,-31.619125366210938,12.990285873413086,5.127693176269531,25.15031623840332,-53.39192581176758,-36.57802963256836,76.58599853515625,-33.195770263671875,12.335081100463867,37.664756774902344,-52.193359375,-40.326576232910156,78.8522720336914,-46.00626754760742,-16.655227661132812,-53.929195404052734,-69.55609893798828,-31.765417098999023,61.037330627441406,23.890056610107422,9.829246520996094,-47.76033401489258,16.378297805786133,-8.244145393371582,-23.01923942565918,-56.24355697631836,-25.45844841003418,-12.952398300170898,72.15080261230469,-47.35710906982422,-57.541690826416016,56.0822868347168,31.90553092956543,-31.953243255615234,8.424582481384277,15.969096183776855,49.039886474609375,-53.638851165771484,-6.9836907386779785,-36.66437530517578,-65.09262084960938,-40.834842681884766,29.252471923828125,-18.72757339477539,-13.173008918762207,-58.43427276611328,-32.978946685791016,-58.73551559448242,-12.256051063537598,-50.569271087646484,4.054516315460205,9.589301109313965,-36.24048614501953,16.557701110839844,-32.300743103027344],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8ca73e3e-3e0a-45c2-8622-43d4d3793521');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "x_vals, y_vals, labels = reduce_dimensions(w2v_model_monica)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=x_vals[:MAX_WORDS], y=y_vals[:MAX_WORDS], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# chandler emmbedings"
      ],
      "metadata": {
        "id": "3pm731K3-L2P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NCCXtDpcugmd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "outputId": "b5b4dd8d-9e68-42cc-ce6b-77db0a725c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning:\n",
            "\n",
            "The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning:\n",
            "\n",
            "The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"04d18dc6-4294-4df4-8459-3d636b8e1db8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"04d18dc6-4294-4df4-8459-3d636b8e1db8\")) {                    Plotly.newPlot(                        \"04d18dc6-4294-4df4-8459-3d636b8e1db8\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>text=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"i\",\"you\",\"the\",\"to\",\"a\",\"and\",\"that\",\"it\",\"no\",\"what\",\"is\",\"oh\",\"me\",\"this\",\"of\",\"we\",\"in\",\"okay\",\"so\",\"just\",\"have\",\"not\",\"my\",\"do\",\"well\",\"know\",\"was\",\"yeah\",\"with\",\"for\",\"hey\",\"be\",\"are\",\"all\",\"on\",\"right\",\"but\",\"i'm\",\"get\",\"your\",\"like\",\"gonna\",\"out\",\"can\",\"i\\u2019m\",\"if\",\"her\",\"think\",\"go\",\"about\",\"here\",\"up\",\"look\",\"it's\",\"uh\",\"don\\u2019t\",\"at\",\"don't\",\"really\",\"she\",\"there\",\"now\",\"he\",\"did\",\"it\\u2019s\",\"yes\",\"see\",\"one\",\"why\",\"how\",\"got\",\"mean\",\"that's\",\"because\",\"when\",\"good\",\"say\",\"want\",\"joey\",\"going\",\"that\\u2019s\",\"him\",\"would\",\"you\\u2019re\",\"then\",\"come\",\"they\",\"time\",\"monica\",\"y'know\",\"ross\",\"you're\",\"great\",\"thing\",\"were\",\"tell\",\"y\\u2019know\",\"some\",\"could\",\"us\",\"guys\",\"little\",\"over\",\"man\",\"our\",\"back\",\"sorry\",\"too\",\"had\",\"or\",\"ok\",\"love\",\"way\",\"should\",\"god\",\"an\",\"as\",\"said\",\"am\",\"guy\",\"who\",\"something\",\"them\",\"more\",\"will\",\"make\",\"we're\",\"big\",\"from\",\"maybe\",\"hi\",\"let\",\"ah\",\"his\",\"take\",\"can\\u2019t\",\"been\",\"never\",\"can't\",\"very\",\"actually\",\"wanna\",\"doing\",\"sure\",\"two\",\"she's\",\"didn't\",\"believe\",\"where\",\"i'll\",\"people\",\"still\",\"we\\u2019re\",\"ya\",\"by\",\"first\",\"last\",\"thought\",\"much\",\"down\",\"has\",\"give\",\"off\",\"work\",\"thanks\",\"night\",\"listen\",\"call\",\"ever\",\"didn\\u2019t\",\"those\",\"anything\",\"other\",\"does\",\"need\",\"room\",\"nice\",\"please\",\"huh\",\"day\",\"wait\",\"again\",\"than\",\"new\",\"joe\",\"he's\",\"talk\",\"stop\",\"any\",\"bye\",\"before\",\"talking\",\"only\",\"into\",\"put\",\"getting\",\"even\",\"alright\",\"funny\",\"i\\u2019ll\"],\"x\":[0.9214704632759094,0.6943532824516296,-1.2136917114257812,0.452248215675354,-0.5982874035835266,-0.30707842111587524,1.3441880941390991,1.3213915824890137,5.253151893615723,1.0589807033538818,5.218621253967285,5.534738540649414,0.35409116744995117,0.8643901944160461,-2.505070686340332,0.194071426987648,-2.165637731552124,1.7272059917449951,1.990383267402649,0.7501928806304932,-0.22434979677200317,3.4525558948516846,-0.8438647985458374,1.2009246349334717,3.826587438583374,1.7762560844421387,5.3681230545043945,3.3637547492980957,-1.5613363981246948,-1.1961742639541626,13.21321964263916,1.3273262977600098,4.835849761962891,-0.26269251108169556,-1.9920200109481812,1.1509826183319092,2.653628349304199,8.392104148864746,-3.5296542644500732,-2.2596962451934814,-1.838509440422058,2.420029640197754,-0.8866342902183533,1.8315409421920776,8.439558982849121,2.014145612716675,-3.123448371887207,4.6198410987854,0.08123075217008591,0.8029400110244751,-0.05466298758983612,-2.8704919815063477,4.128748893737793,7.163418769836426,3.6517386436462402,5.742713928222656,-1.544541358947754,6.90793514251709,4.6193108558654785,-0.95348060131073,3.809056282043457,0.9213613271713257,-1.8055870532989502,2.9666640758514404,4.4181318283081055,4.24126672744751,0.02060813456773758,-0.3350919783115387,17.900205612182617,-1.1878530979156494,2.557659864425659,2.229682445526123,6.82724142074585,2.763298749923706,3.1206860542297363,4.499817848205566,-0.5447768568992615,2.1928770542144775,-1.2034540176391602,3.0850439071655273,7.928565502166748,2.087036609649658,3.1706902980804443,4.4543776512146,0.189167782664299,-2.413480281829834,0.907551109790802,-1.0551745891571045,1.009882926940918,-0.23035554587841034,28.8297061920166,24.640615463256836,1.9364995956420898,-2.071767807006836,3.4900643825531006,-0.30330029129981995,5.71821403503418,7.103766441345215,2.2985692024230957,-5.409173011779785,1.189365267753601,7.387020587921143,15.359224319458008,8.943368911743164,-7.868067741394043,-17.652578353881836,11.044588088989258,19.611387252807617,24.76459503173828,-10.200310707092285,31.82558250427246,-6.724390983581543,-24.693796157836914,15.206954956054688,16.1231632232666,-10.573728561401367,-11.864726066589355,-0.07708191126585007,9.62536907196045,-21.855731964111328,-4.029624938964844,-6.766481876373291,-0.7054244875907898,-4.875615119934082,26.020967483520508,28.119945526123047,29.62169075012207,-28.830472946166992,23.676916122436523,-0.060960233211517334,6.375821590423584,31.3450984954834,-33.618648529052734,-9.59557056427002,-5.892730712890625,12.305012702941895,37.01057434082031,42.56452560424805,19.43062400817871,35.573402404785156,29.308481216430664,9.711771965026855,-1.710465669631958,21.365827560424805,-15.265697479248047,36.06428527832031,17.27650260925293,28.13431739807129,34.63998794555664,31.003273010253906,-12.881438255310059,14.86791706085205,27.31148338317871,23.092483520507812,14.774534225463867,-30.95321273803711,34.0500373840332,-32.08226013183594,22.556324005126953,40.07670593261719,26.02730369567871,-31.30145835876465,9.64896297454834,42.44089889526367,9.073890686035156,-0.6949498653411865,34.812007904052734,-2.953960418701172,38.4909553527832,22.139177322387695,-2.079390287399292,16.708454132080078,-5.02790641784668,14.814628601074219,6.743062973022461,-16.577634811401367,28.90587043762207,-7.307569980621338,2.949219226837158,-7.865922927856445,6.809876918792725,-1.0520561933517456,-3.5374057292938232,-40.892822265625,10.035152435302734,31.245553970336914,12.988953590393066,0.051651179790496826,29.18170928955078,19.201906204223633,30.23692512512207,26.579082489013672,0.03509873151779175,14.078857421875,-8.077122688293457,5.479857921600342,-1.8724908828735352,25.57415771484375,21.631126403808594,38.4005012512207],\"xaxis\":\"x\",\"y\":[-0.12252029776573181,-0.6904443502426147,-2.060462713241577,-1.8224666118621826,-1.6513135433197021,-1.2042654752731323,-0.660351574420929,-1.390114665031433,4.9794793128967285,1.3297810554504395,-2.370130777359009,5.88722562789917,-1.07084321975708,-1.2483142614364624,-3.5371897220611572,-0.10264743119478226,-2.5619008541107178,1.7979848384857178,1.0112069845199585,0.5990462899208069,-0.35110175609588623,0.18282784521579742,-0.8571574091911316,0.13506793975830078,1.114428997039795,0.2799065113067627,-1.0697407722473145,1.8225890398025513,-0.9734787940979004,-3.145763397216797,8.7117338180542,-2.235687255859375,-5.235229015350342,-3.004161834716797,-1.9050225019454956,3.6501638889312744,-0.03644067049026489,-2.3981072902679443,-1.3669006824493408,-1.1976203918457031,-0.0888451635837555,-2.3901689052581787,-2.3611907958984375,-2.8707275390625,2.2724344730377197,-1.3736423254013062,-2.4026358127593994,0.41488581895828247,-2.265526533126831,-2.940762996673584,3.220911741256714,-0.42017078399658203,-0.382712185382843,-2.877548933029175,2.908294677734375,0.11180499941110611,-3.806034564971924,-0.190217062830925,2.8570308685302734,0.18202722072601318,-2.333425998687744,2.8627007007598877,0.7675390839576721,-1.6761622428894043,-3.1487975120544434,4.1338653564453125,0.92385333776474,-4.368794918060303,0.16223938763141632,3.0992066860198975,2.185528039932251,-0.5553659200668335,-3.6832079887390137,0.9372817873954773,-0.9407365918159485,1.811653971672058,1.0098603963851929,-4.817683696746826,1.6907721757888794,-3.0753254890441895,0.4777423143386841,-3.6730332374572754,-4.104854583740234,-4.033390522003174,-3.7130887508392334,-5.665422439575195,-4.823343753814697,-5.026689052581787,-5.820467948913574,14.754535675048828,10.785148620605469,6.597991466522217,2.8851616382598877,-4.6795549392700195,-5.125371932983398,2.137979507446289,-4.151571750640869,-12.570841789245605,-8.303807258605957,-19.217403411865234,-4.004184246063232,29.179067611694336,28.263378143310547,30.85015869140625,-22.579898834228516,13.107986450195312,13.578977584838867,30.497066497802734,-8.523477554321289,-29.38709259033203,0.8837064504623413,14.83183479309082,17.927637100219727,-15.958231925964355,21.35349464416504,18.06278419494629,8.966207504272461,22.126611709594727,2.8883261680603027,15.328529357910156,-24.126262664794922,-8.19500732421875,-21.849727630615234,-27.866012573242188,-20.75661277770996,-4.455222129821777,-10.109719276428223,-15.29258918762207,-22.350385665893555,-5.707723140716553,9.878565788269043,7.782735347747803,26.609914779663086,-36.82207107543945,-25.389577865600586,-19.622779846191406,-1.6524611711502075,-1.3560644388198853,-14.940056800842285,21.4647216796875,0.6216397285461426,-14.761478424072266,9.693910598754883,25.534717559814453,-34.16990280151367,-4.814897537231445,-16.218944549560547,32.60249710083008,-24.91402816772461,-7.595914363861084,-36.55127716064453,-25.419578552246094,-9.266623497009277,-28.630733489990234,-39.4090461730957,-29.363985061645508,-21.433191299438477,0.9275206923484802,-32.400474548339844,15.352340698242188,-14.95238971710205,-6.070745944976807,-39.99286651611328,3.5045156478881836,5.926569938659668,36.81184768676758,4.143222332000732,-39.80052185058594,-10.590875625610352,-3.5126895904541016,-31.025846481323242,-36.07296371459961,-30.84148406982422,-31.279157638549805,-22.46686553955078,14.615427017211914,14.141461372375488,-34.602664947509766,-37.622127532958984,9.288334846496582,42.97188186645508,-27.80513572692871,-28.67367935180664,17.022724151611328,35.663429260253906,11.236088752746582,-15.791662216186523,4.333812713623047,-31.344453811645508,21.29608726501465,-23.52401351928711,23.79334259033203,-29.948591232299805,-23.470434188842773,-31.71135902404785,36.46183395385742,-34.068851470947266,30.116188049316406,11.150617599487305,-19.29175567626953],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('04d18dc6-4294-4df4-8459-3d636b8e1db8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "x_vals, y_vals, labels = reduce_dimensions(w2v_model_chandler)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=x_vals[:MAX_WORDS], y=y_vals[:MAX_WORDS], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick takes"
      ],
      "metadata": {
        "id": "qab8DUas-Yof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a few things to note from the experiments above\n",
        "\n",
        "1. Different corpus create different embeddings representations\n",
        "\n",
        " We can check that words do not cluster in the same way for both characters. for example, \"work\" for Monica is closely related to food such as teeth, food, clear, pizza, and geoffrey (the maitre on her restaurant). But for chandler, the same work is related to more random terms. That's because we as spectators never get to know what chandler does for a living.\n",
        "\n",
        "2. On both 2D diagrams, we can see a heavy clustering of stop words mostly. \n",
        " \n",
        " As \"by, put, out in\" etc. those words actually are used a bunch along the series because of the \"casual\" tone the dialog has.\n",
        "a needed improvement would be to discard such words for a more deep insight into concepts and common terms each character has.\n",
        "\n",
        "3. Interestingly enough, gensim tends to clump together terms on the 2d diagram when more training epochs are used. \n",
        " \n",
        " The terms (the embedding representation actually) is more evenly distributed when fewer epochs are used (that's because of model's weight being uniformly set at the beginning of the training process). \n",
        "\n",
        " Additionally, when we use more training epochs, the embeddings tend to represent better the context of the word they represent, and the similar terms make more sense\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TIiCxDwJ-eRh"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}